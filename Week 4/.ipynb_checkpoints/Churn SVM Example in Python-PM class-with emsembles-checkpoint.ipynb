{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Methods, SVMs, Tuning and CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like R, Python uses packages in data mining/machine learning. The 3 mose common ones are Pandas (manipulation), Scikit Learn (machine learning) and Matplotlit (graphics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mpgartland/Documents/Courses/Predictive Models/PM/Week 4-5'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add packages\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "from sklearn import tree \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scipy.stats as ss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import time\n",
    "from operator import itemgetter\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mpgartland/Documents/Courses/Predictive Models/PM/Week 4-5\n"
     ]
    }
   ],
   "source": [
    "cd '/Users/mpgartland/Documents/Courses/Predictive Models/PM/Week 4-5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data\n",
    "# Churn Calls Data\n",
    "This is a Pandas operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>1</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>175.2</td>\n",
       "      <td>74</td>\n",
       "      <td>29.78</td>\n",
       "      <td>151.7</td>\n",
       "      <td>79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>230.5</td>\n",
       "      <td>109</td>\n",
       "      <td>10.37</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>146.3</td>\n",
       "      <td>128</td>\n",
       "      <td>24.87</td>\n",
       "      <td>162.5</td>\n",
       "      <td>80</td>\n",
       "      <td>13.81</td>\n",
       "      <td>129.3</td>\n",
       "      <td>109</td>\n",
       "      <td>5.82</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>19</td>\n",
       "      <td>171.9</td>\n",
       "      <td>96</td>\n",
       "      <td>29.22</td>\n",
       "      <td>198.4</td>\n",
       "      <td>111</td>\n",
       "      <td>16.86</td>\n",
       "      <td>321.7</td>\n",
       "      <td>76</td>\n",
       "      <td>14.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>41</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>159.3</td>\n",
       "      <td>66</td>\n",
       "      <td>27.08</td>\n",
       "      <td>125.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.70</td>\n",
       "      <td>261.9</td>\n",
       "      <td>76</td>\n",
       "      <td>11.79</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>42</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>129</td>\n",
       "      <td>29.07</td>\n",
       "      <td>183.9</td>\n",
       "      <td>96</td>\n",
       "      <td>15.63</td>\n",
       "      <td>130.2</td>\n",
       "      <td>90</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AK</td>\n",
       "      <td>48</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>37</td>\n",
       "      <td>211.7</td>\n",
       "      <td>115</td>\n",
       "      <td>35.99</td>\n",
       "      <td>159.9</td>\n",
       "      <td>84</td>\n",
       "      <td>13.59</td>\n",
       "      <td>144.1</td>\n",
       "      <td>80</td>\n",
       "      <td>6.48</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AK</td>\n",
       "      <td>50</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>183.6</td>\n",
       "      <td>107</td>\n",
       "      <td>31.21</td>\n",
       "      <td>58.6</td>\n",
       "      <td>118</td>\n",
       "      <td>4.98</td>\n",
       "      <td>202.6</td>\n",
       "      <td>99</td>\n",
       "      <td>9.12</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AK</td>\n",
       "      <td>51</td>\n",
       "      <td>area_code_510</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>12</td>\n",
       "      <td>135.8</td>\n",
       "      <td>60</td>\n",
       "      <td>23.09</td>\n",
       "      <td>200.6</td>\n",
       "      <td>134</td>\n",
       "      <td>17.05</td>\n",
       "      <td>192.4</td>\n",
       "      <td>98</td>\n",
       "      <td>8.66</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>104</td>\n",
       "      <td>36.89</td>\n",
       "      <td>152.3</td>\n",
       "      <td>83</td>\n",
       "      <td>12.95</td>\n",
       "      <td>134.3</td>\n",
       "      <td>109</td>\n",
       "      <td>6.04</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>170.9</td>\n",
       "      <td>71</td>\n",
       "      <td>29.05</td>\n",
       "      <td>201.4</td>\n",
       "      <td>80</td>\n",
       "      <td>17.12</td>\n",
       "      <td>159.0</td>\n",
       "      <td>124</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account_length      area_code international_plan voice_mail_plan  \\\n",
       "0    AK               1  area_code_408                 no              no   \n",
       "1    AK              36  area_code_408                 no             yes   \n",
       "2    AK              36  area_code_415                yes             yes   \n",
       "3    AK              41  area_code_415                 no              no   \n",
       "4    AK              42  area_code_415                 no              no   \n",
       "5    AK              48  area_code_415                 no             yes   \n",
       "6    AK              50  area_code_408                 no              no   \n",
       "7    AK              51  area_code_510                yes             yes   \n",
       "8    AK              52  area_code_408                 no              no   \n",
       "9    AK              52  area_code_415                 no             yes   \n",
       "\n",
       "   number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "0                      0              175.2               74   \n",
       "1                     30              146.3              128   \n",
       "2                     19              171.9               96   \n",
       "3                      0              159.3               66   \n",
       "4                      0              171.0              129   \n",
       "5                     37              211.7              115   \n",
       "6                      0              183.6              107   \n",
       "7                     12              135.8               60   \n",
       "8                      0              217.0              104   \n",
       "9                     24              170.9               71   \n",
       "\n",
       "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "0             29.78              151.7               79             12.89   \n",
       "1             24.87              162.5               80             13.81   \n",
       "2             29.22              198.4              111             16.86   \n",
       "3             27.08              125.9               75             10.70   \n",
       "4             29.07              183.9               96             15.63   \n",
       "5             35.99              159.9               84             13.59   \n",
       "6             31.21               58.6              118              4.98   \n",
       "7             23.09              200.6              134             17.05   \n",
       "8             36.89              152.3               83             12.95   \n",
       "9             29.05              201.4               80             17.12   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                230.5                109               10.37   \n",
       "1                129.3                109                5.82   \n",
       "2                321.7                 76               14.48   \n",
       "3                261.9                 76               11.79   \n",
       "4                130.2                 90                5.86   \n",
       "5                144.1                 80                6.48   \n",
       "6                202.6                 99                9.12   \n",
       "7                192.4                 98                8.66   \n",
       "8                134.3                109                6.04   \n",
       "9                159.0                124                7.15   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                 5.3                 3               1.43   \n",
       "1                14.5                 6               3.92   \n",
       "2                10.5                 1               2.84   \n",
       "3                11.1                 5               3.00   \n",
       "4                 4.6                 6               1.24   \n",
       "5                12.2                 1               3.29   \n",
       "6                 8.7                 3               2.35   \n",
       "7                12.3                 7               3.32   \n",
       "8                11.8                 4               3.19   \n",
       "9                 4.1                 5               1.11   \n",
       "\n",
       "   number_customer_service_calls churn  \n",
       "0                              1    no  \n",
       "1                              0    no  \n",
       "2                              1   yes  \n",
       "3                              1    no  \n",
       "4                              0    no  \n",
       "5                              1    no  \n",
       "6                              1    no  \n",
       "7                              2    no  \n",
       "8                              2    no  \n",
       "9                              2    no  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv(\"Churn_Calls.csv\", sep=',')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'state', u'account_length', u'area_code', u'international_plan',\n",
      "       u'voice_mail_plan', u'number_vmail_messages', u'total_day_minutes',\n",
      "       u'total_day_calls', u'total_day_charge', u'total_eve_minutes',\n",
      "       u'total_eve_calls', u'total_eve_charge', u'total_night_minutes',\n",
      "       u'total_night_calls', u'total_night_charge', u'total_intl_minutes',\n",
      "       u'total_intl_calls', u'total_intl_charge',\n",
      "       u'number_customer_service_calls', u'churn'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# See each collum name\n",
    "print df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 20)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Target\n",
    "In this step I took the target variable and moved it to the first collum. I aslo made a reference to it called targetName. This just helps me with some below steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn</th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>1</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>175.2</td>\n",
       "      <td>74</td>\n",
       "      <td>29.78</td>\n",
       "      <td>151.7</td>\n",
       "      <td>79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>230.5</td>\n",
       "      <td>109</td>\n",
       "      <td>10.37</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>146.3</td>\n",
       "      <td>128</td>\n",
       "      <td>24.87</td>\n",
       "      <td>162.5</td>\n",
       "      <td>80</td>\n",
       "      <td>13.81</td>\n",
       "      <td>129.3</td>\n",
       "      <td>109</td>\n",
       "      <td>5.82</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>19</td>\n",
       "      <td>171.9</td>\n",
       "      <td>96</td>\n",
       "      <td>29.22</td>\n",
       "      <td>198.4</td>\n",
       "      <td>111</td>\n",
       "      <td>16.86</td>\n",
       "      <td>321.7</td>\n",
       "      <td>76</td>\n",
       "      <td>14.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>41</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>159.3</td>\n",
       "      <td>66</td>\n",
       "      <td>27.08</td>\n",
       "      <td>125.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.70</td>\n",
       "      <td>261.9</td>\n",
       "      <td>76</td>\n",
       "      <td>11.79</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>42</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>129</td>\n",
       "      <td>29.07</td>\n",
       "      <td>183.9</td>\n",
       "      <td>96</td>\n",
       "      <td>15.63</td>\n",
       "      <td>130.2</td>\n",
       "      <td>90</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>48</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>37</td>\n",
       "      <td>211.7</td>\n",
       "      <td>115</td>\n",
       "      <td>35.99</td>\n",
       "      <td>159.9</td>\n",
       "      <td>84</td>\n",
       "      <td>13.59</td>\n",
       "      <td>144.1</td>\n",
       "      <td>80</td>\n",
       "      <td>6.48</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>50</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>183.6</td>\n",
       "      <td>107</td>\n",
       "      <td>31.21</td>\n",
       "      <td>58.6</td>\n",
       "      <td>118</td>\n",
       "      <td>4.98</td>\n",
       "      <td>202.6</td>\n",
       "      <td>99</td>\n",
       "      <td>9.12</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>51</td>\n",
       "      <td>area_code_510</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>12</td>\n",
       "      <td>135.8</td>\n",
       "      <td>60</td>\n",
       "      <td>23.09</td>\n",
       "      <td>200.6</td>\n",
       "      <td>134</td>\n",
       "      <td>17.05</td>\n",
       "      <td>192.4</td>\n",
       "      <td>98</td>\n",
       "      <td>8.66</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>104</td>\n",
       "      <td>36.89</td>\n",
       "      <td>152.3</td>\n",
       "      <td>83</td>\n",
       "      <td>12.95</td>\n",
       "      <td>134.3</td>\n",
       "      <td>109</td>\n",
       "      <td>6.04</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>170.9</td>\n",
       "      <td>71</td>\n",
       "      <td>29.05</td>\n",
       "      <td>201.4</td>\n",
       "      <td>80</td>\n",
       "      <td>17.12</td>\n",
       "      <td>159.0</td>\n",
       "      <td>124</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  churn state  account_length      area_code international_plan  \\\n",
       "0    no    AK               1  area_code_408                 no   \n",
       "1    no    AK              36  area_code_408                 no   \n",
       "2   yes    AK              36  area_code_415                yes   \n",
       "3    no    AK              41  area_code_415                 no   \n",
       "4    no    AK              42  area_code_415                 no   \n",
       "5    no    AK              48  area_code_415                 no   \n",
       "6    no    AK              50  area_code_408                 no   \n",
       "7    no    AK              51  area_code_510                yes   \n",
       "8    no    AK              52  area_code_408                 no   \n",
       "9    no    AK              52  area_code_415                 no   \n",
       "\n",
       "  voice_mail_plan  number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "0              no                      0              175.2               74   \n",
       "1             yes                     30              146.3              128   \n",
       "2             yes                     19              171.9               96   \n",
       "3              no                      0              159.3               66   \n",
       "4              no                      0              171.0              129   \n",
       "5             yes                     37              211.7              115   \n",
       "6              no                      0              183.6              107   \n",
       "7             yes                     12              135.8               60   \n",
       "8              no                      0              217.0              104   \n",
       "9             yes                     24              170.9               71   \n",
       "\n",
       "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "0             29.78              151.7               79             12.89   \n",
       "1             24.87              162.5               80             13.81   \n",
       "2             29.22              198.4              111             16.86   \n",
       "3             27.08              125.9               75             10.70   \n",
       "4             29.07              183.9               96             15.63   \n",
       "5             35.99              159.9               84             13.59   \n",
       "6             31.21               58.6              118              4.98   \n",
       "7             23.09              200.6              134             17.05   \n",
       "8             36.89              152.3               83             12.95   \n",
       "9             29.05              201.4               80             17.12   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                230.5                109               10.37   \n",
       "1                129.3                109                5.82   \n",
       "2                321.7                 76               14.48   \n",
       "3                261.9                 76               11.79   \n",
       "4                130.2                 90                5.86   \n",
       "5                144.1                 80                6.48   \n",
       "6                202.6                 99                9.12   \n",
       "7                192.4                 98                8.66   \n",
       "8                134.3                109                6.04   \n",
       "9                159.0                124                7.15   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                 5.3                 3               1.43   \n",
       "1                14.5                 6               3.92   \n",
       "2                10.5                 1               2.84   \n",
       "3                11.1                 5               3.00   \n",
       "4                 4.6                 6               1.24   \n",
       "5                12.2                 1               3.29   \n",
       "6                 8.7                 3               2.35   \n",
       "7                12.3                 7               3.32   \n",
       "8                11.8                 4               3.19   \n",
       "9                 4.1                 5               1.11   \n",
       "\n",
       "   number_customer_service_calls  \n",
       "0                              1  \n",
       "1                              0  \n",
       "2                              1  \n",
       "3                              1  \n",
       "4                              0  \n",
       "5                              1  \n",
       "6                              1  \n",
       "7                              2  \n",
       "8                              2  \n",
       "9                              2  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# designate target variable name\n",
    "targetName = 'churn'\n",
    "# move target variable into first column\n",
    "targetSeries = df[targetName]\n",
    "del df[targetName]\n",
    "df.insert(0, targetName, targetSeries)\n",
    "expected=targetName\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#EDA\n",
    "Just a touch of EDA. This is the distribution of the target. As you can see, the datset is imbalanced and the target class of interest \"yes\" is in the minority (a common occurance in classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x11992e610>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSWqcQS9JjTPoJalxBr0kNe7/A9HPOTMfL4IlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11624e910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gb = df.groupby(targetName)\n",
    "targetEDA=gb[targetName].aggregate(len)\n",
    "plt.figure()\n",
    "targetEDA.plot(kind='bar', grid=False)\n",
    "plt.axhline(0, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Preprocessing\n",
    "The below two steps are for preprocessing. The first cell changes the yes/no of the target to numeric. I needed to do this as some models require the target to be numeric. The second cell takes all the category features and creates dummies with them. This is stock code I have used for long time (and I did not write it). It is nice because it will take any dataframe of any size and handle categorial features. I do not have to change a single line in it. It can be used generically on bascially any dataframe. Saves a lot of time of coding each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le_dep = preprocessing.LabelEncoder()\n",
    "#to convert into numbers\n",
    "df['churn'] = le_dep.fit_transform(df['churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform data transformation\n",
    "for col in df.columns[1:]:\n",
    "\tattName = col\n",
    "\tdType = df[col].dtype\n",
    "\tmissing = pd.isnull(df[col]).any()\n",
    "\tuniqueCount = len(df[attName].value_counts(normalize=False))\n",
    "\t# discretize (create dummies)\n",
    "\tif dType == object:\n",
    "\t\tdf = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "\t\tdel df[attName]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test/Train\n",
    "I split the data into a 60/40 train test. The features are stored in \"features_train\" and \"features_test\". The targets are in \"target_train\" and \"target_test\". I used a biggest test when I have an imbalanced set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split dataset into testing and training\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    df.ix[:,1:].values, df.ix[:,0].values, test_size=0.40, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a view of the size of each test/train set.\n",
    "Note there are now 73 features, and the test set is imbalanced (14.6%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 73)\n",
      "(3000, 73)\n",
      "(2000,)\n",
      "(3000,)\n",
      "Percent of Target that is Yes 0.146\n"
     ]
    }
   ],
   "source": [
    "print features_test.shape\n",
    "print features_train.shape\n",
    "print target_test.shape\n",
    "print target_train.shape\n",
    "print \"Percent of Target that is Yes\", target_test.mean()\n",
    "#data.groupby(['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Models\n",
    "All the models are done in Sci-Kit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Decision Tree\n",
    "I created a decision tree from the data. The accurancy of the model was 921%, while the test data classified at 92%. However notice that the \"yes\" class (the class I am interested in) only properly classified at 74% (specificity) and .71 (recall). That is so-so. Again, not uncommon with imbalanced data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy Score 0.922\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Fail = no       0.95      0.96      0.95      1708\n",
      " Fail = yes       0.74      0.73      0.73       292\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree train model\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(features_train, target_train)\n",
    "#DT test model\n",
    "target_predicted_dt = clf.predict(features_test)\n",
    "print \"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt)\n",
    "# print classification report\n",
    "target_names = [\"Fail = no\", \"Fail = yes\"]\n",
    "print(classification_report(target_test, target_predicted_dt, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation of Decision Tree\n",
    "I cross validated with 10 repeats. You can see the OOB score for each repeat and the mean. The mean is .92, which is quite close to the orginal model. I am not going to worry about over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.93023256  0.910299    0.92358804  0.94684385  0.92026578  0.93311037\n",
      "  0.92307692  0.91304348  0.92976589  0.91638796]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92466138512650142"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(clf, features_train, target_train, cv=10)\n",
    "print \"Cross Validation Score for each K\",scores\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visual of Confusion Matrix for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1632   76]\n",
      " [  80  212]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAADvCAYAAAAD3jo2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGElJREFUeJzt3Xm8JGV97/HPdxZgWIZNlovIDHtQ2SY6oubiXBBEQUzM\nNYJewqIhkcSYcF1AyR0nURFf94oiXhN0nCDKGpIIVxQkyahElpFdduGyCgOCIosZZs788sfznJme\nM919qrpPnerq832/XvWa01VPVz09r65fP0tV/RQRmJmVMa3uCphZ8zhwmFlpDhxmVpoDh5mV5sBh\nZqU5cJhZaQ4cNZG0kaTLJf1K0kV97Oc9kr43kXWri6TfkXRX3fWw8TlwjCOfmMskPSfpMUnfkfTG\nCdj1fwe2AbaMiHf3upOIOD8iDpuA+lRK0mpJu3QrExHXRMRek1WnppO0WNJySbeNWf9BSXdJul3S\nZ1vWnyrpvrzt0Jb18yTdJuleSV8ocmwHji4knQx8HvgUsC2wE/Bl4O0TsPs5wL0xda7A6/o5JU2f\nrIoMgi2kUPHlwQ67WQK8pXWFpAWk7+feEbE38L/z+r2APwD2At4K/F9Jym/7CvC+iNgD2EPSOvts\nKyK8tFmA2cBzwDu7lNkA+ALwGPAocCYwM297E/AIcDKwPJc5Nm/7JLACeAn4NXA8sBA4r2Xfc4DV\nwLT8+jjg/lz+fuDovP5Y4Ect73sDcAPwS+B64PUt2/4N+Gvgmryf7wFbdfhso/X/SEv935G/dPcA\nvwBObSn/WuDH+biPAV8CZuRtP8if5fl83He17P+jwOPAuaPr8nt2AZ4G9suvdwCeBA6s+7sxQd+v\n+FTBJZ2mHfczB7it5fVFwEFtyp0CfKzl9XeB1wHbA3e2rD8K+Mp49XeLo7PXAxsC/9ylzGnAfGAf\nYN/892kt27cHNiN96d9PivKbR8Qngc8AF0bE7IhYksuP/VUOAEkbA18E3hIRs0nB4ZY25bYE/h8p\nmG1NCmTfyetHHU0KNtvkz/fhLp9ve1Jw3IEU2L4KvBfYHzgQ+CtJc3LZEeAvgK1I/3cHAScBRMSb\ncpm98+e9pGX/W5Bacie2fpaIeIAUVL4paRbp13VJRPywS30bZWbBpaQ9gAMlXSfp3yT9dl7/clKg\nHvVYXvdy0o/eqEfzuq4cODrbGvhFRKzuUuY9wKKIeDoingYWAce0bH8J+JuIGImI75J+cffssT4j\nwN6SNoqI5RHRbhDxcFL35/yIWB0RFwJ3s27XaklE3B8RK4CLgf26HPMl4DMRMQJcCLwM+EJEvBgR\ndwJ3kgImEXFTRNwQycPAOaQWRCuNeT0CLIyIlbk+64iIxcDPSC2n7Vg3KDfejIJLD7vdMiIOIAXe\nS8Yp35Me6jVlPA28TNK0LsFjB+DhltcP5XVr9jHmvS8Cm5atSES8KOndpG7D1yVdA3w4Iu5pU5+H\nxqx7iHV/QZ4oUZ+nI7dfgd/kf59s2f6b0fdL2p00HvQaYBbpu3Vjt88FPBURK8cp8zXg28CJBco2\nyqwO6+/NS48eAf4RICKWSRqRtDWphbFTS7kd87rHgFe0Wd+VWxydXUsah/jdLmUeI/UxR80Bft7j\n8V4ANm55/V9aN0bE9yPiUFLz/h7SL/pYPwfmjlm3EwW+CBPgK8BdwK4RsQXwCdZvYYw13oDpJqRu\n12Lgk5K2mIiKDopOXZNXAb/XsoxDrPv//M+kbiKS9gA2yK3hy4B3S9pA0s7AbsANEfEE8Kyk+Xmw\n9A9JgborB44OIuLXpH79lyW9Q9IsSTMkvbVliutC4DRJL5P0MuCvgPN6POQtpL7pKyRtThrMAkDS\ntpKOzGMdK0ldnnatoCuA3SUdJWl6bqXsBVzeY53K2Az4dW4d/RbwgTHbnyANeJZxFunLfSLps/1d\n/9UcHP12VSSdTxqQ3kPSw5KOB74O7CLpduB8UiAgdy0vJnUvrwBOamlN/ikpON8L3BcR414X5K5K\nFxHxeUmPk/rW3yTNstwIfDoX+RTphLmN9Ot5ccu2trvscqyr84VgtwFPAWewdmxiGml25ty8j1tY\n/8QkIp6RdATphPsKaXzg8Ij45XjHL6jt4G32YeAcSR8FbiYF1YNatn8S+IakjUgDoU91O5CkI4FD\ngb3zqpOBmyUdHREX9PwJBkgPA5/riIj3dNh0TLuVEXE6cHqb9Tey9v+5EK0NOlaEpMNIzedpwOKI\nOKPmKg0VSYuBI4DlEbFP3fWpiqS4sGDZo4CIGK/bN6ncVSlB0jTgbNJFN68Cjs7Ncps4613UNKwq\nmo6dFA4c5cwn9QEfyiP8F5IuirIJEhHXkC4iG3pNDhwe4yhn7EU0j5KCiVlpnaZjm8CBw6wmTT75\nmlz3OnS6iMastEHthhThwFHOMmC3fH/G46QB76PrrdJQGntR01Bq8snnwdES8j0bfwZcBdxBuknN\nD56ZQB0uahpKTR4c9XUcZjWQFLcWLLsvg3cdR5NbS2aNNqitiSIcOMxq4ulYMyvNLQ4zK63JJ1+T\n627WaDOLnn2rKq1GTwYicEjy1I4NhTKzHzMcOPq3sO4KlLAUWFBzHcpa1Kj/YWjq/3IZMxucEGJg\nAofZVFO4xTGAGlx1s2abuWHdNeidA0cP5tZdgSlhbt0VqF6Dz74GV70+c+uuwJQwt+4KVK/BZ59v\ncjOrS5+POe+UdDpv+5850fdWLeucdNqs8aYXXDpr+3xWSTsCh9CSnGuik047cJjVpc8WR5fns55J\nyvrX6h2kx0CsiogHgfuA+ZK2BzaLiGW53DfonoRsTdXNrA4VzKrkfDSPRMTtaxsUQHpe7rUtr0eT\nTq+ih6TTDhxmdZngs0/SLODjpG5KpRw4zOrS4exb+iws/XVPe9yVNB11ax6/2BG4SdJ8JjjptAOH\nWV06DHwu2CotoxZ1P43XPJ81In5KSkqeNkj/H5gXEb+UdBnwLUmfJ3VFRpNOh6Rnc3BZRso1e9Z4\nVffgqFld+p+OHe/5rMHaoOKk02ZDoc+zr0vS6dHtu4x5PWFJpx04zOrS4LOvwVU3azjf5GZmpTX4\n7Gtw1c0azg/yMbPSGnz2NbjqZg3X4LOvwVU3azh3VcystAaffQ2uulnDbVR3BXrnwGFWF3dVzKy0\nBp99Da66WcM1+OxrcNXNGs5dFTMrrcFnX4OrbtZwDT77Glx1s4bz3bFmVlqDz74GV92s4Rp89jW4\n6mYN51kVMyutwWefn3JuVpcKkk5L+lxOKn2LpEslzW7Z5qTTZo1XTdLpq4BXRcR+pPywpwJIeiVO\nOm02BDYquHTQLul0RFwdEavzy+tImdkAjsRJp82GQPVn3wnABflvJ502GwoVzqpI+gSwMiIuGLdw\nDyoPHJIOA75A6hYtjogzqj6mWSN0Sjp9e1p6Jek44G3AQS2rOyWXHryk05KmAWcDBwM/B5ZJ+nZE\n3F3lcc0aocPZt2D/tIxadGHXvaxJOg1rfqg/AhwYEStayo0mnT6TCUg6XXWLYz4pie1DAJIuBN4B\nOHCY9dlVyUmnFwBbS3oYWAh8HNgA+H6eNLkuIk6KiDsljSadXsn6Saf/njQUe8UgJJ1+OfBIy+tH\nScHEzPp85miHpNNLupR30mmzxvMl5x09BuzU8rrjwMvSlr/n5sVssD2Ylx41+Ge76qovA3aTNAd4\nHDgKOLpdwQUVV8Rs4s1l3Z+4H5R7uwNHexExIunPSJfBjk7H3lXlMc0aw4GjszxCu2fVxzFrHI9x\nmFlpDT77Glx1s4bzM0fNrLQGn30NrrpZwzX47Gtw1c0arsFnX4OrbtZs4VkVMytrpMFnX4OrbtZs\nDhxmVtqKDTcoWPKlSuvRCwcOs5qMTG/uIIcDh1lNRhp8zbkDh1lNVjlwmFlZIw0+/Zpbc7OGa3JX\nxZnczGoywvRCSycdcsduKekqSfdIulLS5i3bnDvWrOlWsEGhpYt2uWNPAa6OiD2Bf2Wyc8dKmt1t\nGW/HZtbdCDMKLZ20yx1LSj9ybv77XNbmgZ203LF3AEFLspeW18G6DyE2s5IqGuPYNiKWA0TEE5K2\nzesnJ3dsRLyi0zYz698kDY7G+EXKKzSrIukoYJeI+IykHYHtchIXM+tRp+s4blz6PDcufaHX3S6X\ntF1ELM/dkCfz+snNHSvpbGAmcCDwGeBF4G+B1xb4EGbWQafxi/0WbMF+C7ZY8/pri57qtpt1cseS\ncsQeB5wBHAt8u2X9pOaOfUNEzJN0M0BEPCOp6N05ZtZBv12VDrljPwtcIukE4CHSTAp15I5dmbPO\nR67s1sDqwp/OzNp6qftU67g65I4FeHOH8pOaO/bLwKXANpIWkSLYojIHMbP1DfW9KhHxDUk3sjaK\nvSsiflpttcyG31S4V2U6qV8U+GpTswkx1PeqSPoEcAGwA2mq5nxJp1ZdMbNh1++9KnUq0uL4Q2D/\niHgRQNKngZtpM8hiZsUN9RgH8PiYcjPyOjPrw0sNzgHZMXDkC0UCeAa4Q9KV+fWhpAtFzKwPg9oN\nKaJbi2N05uQO4Dst66+rrjpmU8dQdlUiYvFkVsRsqhnq6VhJuwKfBl5JuiQVgPzQDzPrUZO7KkWu\nyfh70pOGRHpy0MXARRXWyWxKaPJ0bJHAsXFEXAkQEfdHxGmkAGJmfWhy4CjSyVqRb3K7X9KfkO7V\n36zaapkNvxXDOB3b4i+BTYA/J411bA6cUGWlzKaCQW1NFFHkJrfr85/PAcdUWx2zqWMoA4ekf6LL\n8woj4p2V1MhsihjK6ziAsyetFmZT0FBexxER/zKZFVnEwsk83BT0/rorMAWUe77VUHZVzKxaDhxm\nVto46R0HWuGneUlq7qSz2QDqNwWkpL+U9NOcMPpbkjboJel0L4o8AWy+pNtJuSaRtK+kL/VzUDPr\n78pRSTsAHwTmRcQ+pN7D0fSWdLq0Ii2Os4AjgKcBIuJW4L/1ekAzSybgkvPpwCaSZgCzSFd1l0o6\n3WvdiwSOaRHx0Jh1I70e0MySVUwvtLQTET8H/g/wMClgPBsRV5PSs65JOg20Jp1+pGUXo0mne1Jk\ncPSRnB4uJE0nNY/u7fWAZpb0cx2HpC1IrYs5wLOk7G3vZf2LNmtLOv0BUndlJ2A5cHVeZ2Z96NQN\neXzpvTyxdNzf5jcDD0TEM7DmSu83UD7pdE+K3KvyJHBUrwcws/Y6pYDcesGr2XrBq9e8vnXRd9oV\nexg4QNJGwArgYNKzgJ+nRNLpXute5AlgX6VNcyciTuz1oGbW370qEXGDpH8gpSpZmf89h/TIi4tL\nJp0urUhX5eqWvzcCfo91B1nMrAf93qsSEYtY/zr3ZyiZdLoXRboq6zwmUNJ5wDUTcXCzqWyqXXK+\nM7DdRFfEbKoZ6sAh6ZesHeOYRmoKnVJlpcymgmF9Hgf5ktR9WTtts7qfARUzW2son8cBEBEh6YqI\neHW3cmZWXqfp2CYoEvJukbR/RNxceW3MppCh7KpImhERq4D9gWWS7gdeICVmioiYN0l1NBtKw9pV\nuQGYR7qrzswm2LDOqghS9rZJqovZlDKsgWMbSSd32hgRn6+gPmZTxrAGjunApuSWh5lNrGFNAfl4\nRPz1pNXEbIoZ1haHWxpmFRrWwHHwpNXCbAoayus4Rp8sZGbVGNbrOMysQsPaVTGzCjlwmFlpK14a\n7pvczKwCI6uae/o1t+ZmDTeyqrldlcJJp81sYo2sml5o6UTS5pIuyUmk75D0uoFJOm1m1Vi1cnqh\npYsvAldExF6kJ/XdzQAlnTazCqwemVFoaUfSbOC/RsQSgJxM+lkGKOm0mVVh1fRiS3s7A7+QtETS\nTZLOkbQxA5R02syq8B99nX4zSA/a+tOI+ElO7XgKA5R02syqsKrD+huWwrKl4737UeCRiPhJfn0p\nKXBMStJpDUK2A0kBC+uuxpB7f90VmAJeQUQUGnCUFNxa8NzbV233K+kHwB9FxL2SFgIb503PRMQZ\nkj4GbBkRp+TB0W8BryN1Ub4P7N5ruhO3OMzq0qnFUdyfkzLQzwQeAI4nPYCr8qTTlbY4JC0GjgCW\nR8Q+Xcq5xVE5tziqV7LFcV3Bc++A9i2OOlU9q7IEeEvFxzBrppGCywCqtKsSEddImlPlMcwaq/+u\nSm08xmFWl/+ouwK9c+Awq4tbHBNhacvfc/NiNsiuzUuPHDi6EoWemL6g6nqYTbDX52XUmeXe3uDA\nUemsiqTzgR8De0h6WNLxVR7PrFFWFlwGUNWzKu+pcv9mjTagU61FDNAYh9kU0+CuigOHWV08HWtm\npbnFYWalOXCYWWkOHGZW2oBOtRbhwGFWF0/HmllpnlUxs9I8xmFmpXmMw8xK8xiHmZXW4K6KM7mZ\n1WVVwaULSdNyJrfL8msnnTYbahNzW/2HSCkPRjnptNlQW1Fw6UDSjsDbgK+1rHbSabOh1n9X5Uzg\nI6ybH9ZJp82GWqduyJNL4amlXd8q6XBSorNbJC3oUtRJp82GSqfp2K0XpGXUXYvalXojcKSktwGz\ngM0knQc8MRlJp91VMatLH12ViPh4ROwUEbsARwH/GhHHAJcDx+VixwLfzn9fBhwlaQNJOwO7ATf0\nWnW3OMzqUs11HJ+l6UmnC1fCSacngZNOV69k0uk3Fzz3rh68pNNucZjVpctU66Bz4DCrS4MvOXfg\nMKuL7441s9J8d6yZleauipmV5sBhZqV5jMPMSvN0rJmV5q6KmZXmroqZlebpWDMrzV0VMyvNgcPM\nSvMYh5mV1uAWh58A1pMH667AFHBt3RWwLhw4evJg3RWYAhw4BpkDh5mV5jEOs9o0d3R0gJ45atZ8\npZ45yosF97rxevvNWdy+AWwHrAa+GhFnSdoSuAiYQ+pT/0FEPJvfcypwAmlY9kMRcVXBCqxf/0EI\nHGZTTQoczxYsvXm7wLE9sH1OyLQpcCMp/ePxwNMR8TlJHwO2jIhTcu7YbwGvJeVUuRrYvdcnnXuM\nw6w2vym4rC8inoiIW/LfzwN3kQLCpOSO9RiHWW0mZoxD0lxgP+A6xuSOldSaO7Z1qsq5Y82aqf8r\nwHI35R9IYxbPtxkvdO5Ys+HSqcVxfV66kzSDFDTOi4jRVI/LnTu2oSSNSLpJ0u2SLpK0UR/7epOk\ny/Pfb5f00S5lN5f0gR6OsVDSyUXXjymzRNI7SxxrjqTby9ZxOHVKFvvbwEktS0dfB+6MiC+2rLuM\nScgd68BRjRciYl5E7E36WfmTsQUklUnpFwARcXlEfK5LuS0Z55s2IDyVB6SvRpFlfZLeCLwXOEjS\nzfmH6jDgDOAQSfcAB5NyyRIRdwKjuWOvoM/csQ4c1fsRsFv+pb1b0rn5F3dHSYdI+rGkn+SWycYA\nkg6TdJeknwBrfs0lHSvpS/nvbSX9o6Rb8hfnAOB0YNf8JTojl/uwpBtyuYUt+/qEpHsk/RDYc7wP\nIen9eT83S7pkTCvqEEnL8uc7PJefJulzkq7Px/6jvv8nh05fsyr/HhHTI2K/iNg//1B9LyKeiYg3\nR8SeEXFoRPyq5T2nR8RuEbFXP9dwgANHVQRr+qBvBUab5rsDZ+eWyIvAacDBEfEa0jz8yZI2BM4B\nDs/rtx+z79FfibOApRGxHzAPuAM4BfhZ/hJ9TNIhpLn6+cD+wGsk/Y6keaQs5vsAh5Pm9sdzaUTM\nj4j9gbuB97VsmxMRrwWOAP5W0gZ5+68i4nWkab8TJc0pcJwppFNXZewyeDw4Wo1Zkm7Kf/8IWEya\n+nowIpbl9QcArwT+PXdbZpKmy34LeCAiHsjlvgm0+7U+CDgGIDc5n5O01Zgyh5JaAzeRgtkmpOA1\nG/iniFgBrJB0WYHPtI+kvwG2yPu5smXbxbkeP5N0f/4MhwJ7S3pXLjM7H/u+AseaIpp7ybkDRzVe\njIh5rSvykMYLrauAqyLivWPK7Zu3jadI/1TA6RHx1THH+FCB9461BDgyIn4q6VjgTR3qovxawAcj\n4vtjju1WxxqD2Zoowl2VanQ68VvXXwe8UdKuAJI2lrQ7qRswJ498AxzdYV//Qh4IzeMJs4HngM1a\nylwJnCBpk1xuB0nbAD8EflfShpI2A95e4DNtCjwhaSZpUK7Vu5TsCuwM3JOPfVLuriFpd0mz2vw/\nTGG9D47WzS2OanRqDaxZHxG/kHQccEEe1wjgtIi4T9IfA1dIeoHU1dm0zb7+AjhH0vtIP10fiIjr\n82DrbcB38zjHXsC1ucXzHPA/IuJmSRcDtwHLKTYt979yuSdJFxm0BqiH87bNgD+OiJckfQ2YC9yU\nu2JPsvbyZ8+qAE1ucfgmN7MapCs8Ly1Y+vcL33U7WdziMKtN+6nWJnDgMKvNYI5fFOHAYVab5o5x\nOHCY1cYtDjMrzS0OMyvNLQ4zK80tDjMrrbnTsb4AzKwGkh4kpTAo4qGImFtdbcpz4DCz0nyTm5mV\n5sBhZqU5cJhZaQ4cZlaaA4eZlfafXkF+14y4lrYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119938250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display confusion matrix\n",
    "cm = confusion_matrix(target_test, target_predicted_dt)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest\n",
    "Using the same data, I built a random forest with 500 bootstrapped trees. Notice I parallelized this to 4 cores as big random forest can be computationally expensive. \n",
    "\n",
    "My overall results went up by 3% over the decision tree. Also, my minory target precision, but the recall decresed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.952\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.95      1.00      0.97      1708\n",
      "Churn = yes       0.98      0.68      0.81       292\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2000\n",
      "\n",
      "[[1704    4]\n",
      " [  92  200]]\n"
     ]
    }
   ],
   "source": [
    "# train random forest model\n",
    "#paralleized to 4 cores \n",
    "rf = RandomForestClassifier(n_estimators= 500, n_jobs=-1,oob_score=True)\n",
    "rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_rf)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names))\n",
    "print(confusion_matrix(target_test, target_predicted_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation of Random Forest\n",
    "I cross validated with 10 repeats. You can see the OOB score for each repeat and the mean. The mean is .949, which is quite close to the orginal model. I am not going to worry about over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.94684385  0.94352159  0.93687708  0.95681063  0.94019934  0.95317726\n",
      "  0.95317726  0.93979933  0.94983278  0.9632107 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94834498161090663"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify RF with cross validation\n",
    "scores_rf = cross_val_score(rf, features_train, target_train, cv=10, n_jobs=-1)\n",
    "print \"Cross Validation Score for each K\",scores_rf\n",
    "scores_rf.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visual of Confusion Matrix for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1704    4]\n",
      " [  92  200]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAADvCAYAAAAD3jo2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVpoTh5mV9v/FIo2TJIPHJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119fc8ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display confusion matrix\n",
    "cm = confusion_matrix(target_test, target_predicted_rf)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Model Tuning\n",
    "You can tune any argument in these models. I did a grid search only on max_features (mtry in R). I parallelized the job to 4 cores for speed. You can see that max_features (mtry) of 5 had the best results. But frankly was very little difference from the other parameter results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.104315 seconds\n",
      "[mean: 0.88967, std: 0.00843, params: {'max_features': 2}, mean: 0.90167, std: 0.00844, params: {'max_features': 3}, mean: 0.91267, std: 0.00893, params: {'max_features': 4}, mean: 0.92267, std: 0.00961, params: {'max_features': 5}]\n"
     ]
    }
   ],
   "source": [
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_features\": [2, 3, 4, 5]}\n",
    "start_time = time.clock()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid,n_jobs=-1)\n",
    "\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "print time.clock() - start_time, \"seconds\"\n",
    "print grid_search.grid_scores_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#KNN\n",
    "I performed KNN on K=3 and K=5. For both K's the accurancy was 85% and 87% respectively and I still have problems with the minority class. KNN and Decision Tree perform about the same. I find this to be true frequently, which is why I use them as my base comparative models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.89      0.96      0.93      1708\n",
      "Churn = yes       0.59      0.31      0.41       292\n",
      "\n",
      "avg / total       0.85      0.87      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh3 = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh3.fit(features_train, target_train)\n",
    "# test KNN 3\n",
    "target_predicted_knn3 = neigh3.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_knn3)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_knn3, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.882\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.89      0.98      0.93      1708\n",
      "Churn = yes       0.74      0.30      0.42       292\n",
      "\n",
      "avg / total       0.87      0.88      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh5 = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh5.fit(features_train, target_train)\n",
    "# test KNN 3\n",
    "target_predicted_knn5 = neigh5.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_knn5)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_knn5, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#More Details\n",
    "Now that we know our random forest was the best model of the three I ran, I will gather some other information. Below is a non-ordered list of feature importance. I only showed 20 for purposes of space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('account_length', 0.032789172064762132),\n",
       " ('number_vmail_messages', 0.017500131884187396),\n",
       " ('total_day_minutes', 0.13290161799275291),\n",
       " ('total_day_calls', 0.030301080041210002),\n",
       " ('total_day_charge', 0.12090194065432341),\n",
       " ('total_eve_minutes', 0.055091580355634266),\n",
       " ('total_eve_calls', 0.028840394034212617),\n",
       " ('total_eve_charge', 0.05389316818857065),\n",
       " ('total_night_minutes', 0.036364245014953347),\n",
       " ('total_night_calls', 0.03027458495745073),\n",
       " ('total_night_charge', 0.036656918932623989),\n",
       " ('total_intl_minutes', 0.041831479509182153),\n",
       " ('total_intl_calls', 0.044944683680972361),\n",
       " ('total_intl_charge', 0.041167990984230587),\n",
       " ('number_customer_service_calls', 0.10018735125945424),\n",
       " ('state_AK', 0.000747855717265558),\n",
       " ('state_AL', 0.00079086315829090875),\n",
       " ('state_AR', 0.0019844137993300565),\n",
       " ('state_AZ', 0.0018459616315574944)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show importance of each feature in Random Forest\n",
    "zip(df.columns[1:20], rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ROC curve for Random Forest\n",
    "Finally a ROC curve that shows the lift I get from the Random Forest model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.923\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEZCAYAAACNebLAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4FGW2wOHfCasICQnIDgEFkSWAiMigSBRQcFAcRRHQ\nUXFAcXAZGRFHUJzrho4OKqIgoBcXZARF5gqKMgYHkEWNLCHIJgQiAoawGkJIzv2jmpCE7qSzdFen\nc97nqSdd1V9XHYqkTn9LfSWqijHGGFNQhNsBGGOMCU2WIIwxxnhlCcIYY4xXliCMMcZ4ZQnCGGOM\nV5YgjDHGeGUJwhhjjFeWIExYEJEdIvKbiBwWkZ9F5C0RqVGgTHcRWeIpky4in4hImwJlaonIJBHZ\n6Sm3RUReEpGYQo59v4isF5GjIpIiInNEpF2g/q3GBIslCBMuFPi9qkYCnYALgUdPvSkivwM+Bz4G\nGgItgHXAchFp7ilTBfgP0Aa4yrOv3wG/Al29HVREXgHuA0YB0cD5wHzg98X9B4hIpeJ+xphAEruT\n2oQDEfkJuEtV/+NZnwi0VdVrPetfA2tV9b4Cn1sI7FPVO0TkT8D/AOeqaoYfx2wJbAIuUdXvfJT5\nCnhHVWd61m8H/qSqPTzrOTjJ5UGgEk4SO6aqD+fZx3wgQVUniUhD4FXgcuAIMElVX/XvLBlTPFaD\nMGFHRJoA/YAtnvWzgO7AXC/F/wX08bzuBXzmT3LIU36Xr+RQiILfygYAFwNtgdnAzafeEJHawFXA\nbBER4N9AIk4tqBfwgIj0wZgAsARhwsl8ETkMpAB7gQme7TE4v+t7vHxmD1DX87qOjzK+FLe8L8+o\n6iFVzVTV/wIqIpd53hsIrFDVvTjNXHVV9WlVzVbVHcB04JYyiMGYM1iCMOFkgKffoCdwAacv/OlA\nDs637oIa4vQxAKT5KONLccv7srvA+hxgsOf1EOA9z+tmQGMROeBZ0nH6WeqVQQzGnMEShAknAuD5\nFv6/wIue9d+Ab4CbvHzmZuBLz+svgas9TVL+WAI0EZHOhZQ5BuQdTdXAS5mCTU6zgYEi0gy4BJjn\n2b4L2K6qMZ4lWlWjTvWzGFPWLEGYcDUJ6CMicZ71scDtIjJKRGqKSLSIPAV0A/7uKfMOzkV4noi0\nFkcdEXlURPoWPICqbgWm4PQP9BSRKiJSTUQGicgYT7EfgBtE5CxPp/ZdRQWuqj/g1E6m4/SJHPa8\ntRo4IiJjRKS6iFQSkXYi0qUkJ8iYoliCMOEi37dwVf0VpxbxuGd9OXA1cCNOv8FPQEfgUlXd5ilz\nAuiNMzLpC+AQsBKnr2GV14OqPgBMBl7DacraClyP05kM8E8gC/gFeAt4t7C483gfpxP6vdyCqjlA\nf5xhvD8B+4A3gUgf+zCmVGyYqzHGGK+sBmGMMcYrSxDGGGO8sgRhjDHGK0sQxhhjvKrsdgD+EhHr\nTTfGmBJQVSnJ58pVDUJVbVHliSeecD2GUFnsXNi5sHNR+FIa5SpBGGOMCR5LEMYYY7yyBFEOxcfH\nux1CyLBzcZqdi9PsXJSNcnMntYhoeYnVGGNChYigodhJLSIzRGSviKwrpMwrnuf+/iAinQIZjzHG\nGP8FuonpLZwJ0rwSkX7AearaCrgbeCPA8RhjjPFTQBOEqi7DmeHSlwHALE/ZVUCUiNQPZEzGGGP8\n4/aNco1x5t8/JdWzba874RhjTPmjCjt2wLZtzutTMjKOlWq/bieIYpkwYULu6/j4eBupYIwJSydO\nwJ49kJoKu3c7P3/5BXJyziyXlATffw9nnQWtW8OhQwmkpycAcPDg8lLFEfBRTCISC/xbVTt4ee8N\n4CtVneNZ3wT0VOcB7QXL2igmY0y5pgpHjjgX/1MXfm8/DxyA+vWhSRNo3Nj5Wb8+VC7wlb5SJWjT\nBi68EBp4e5gtpRvFFIwahHgWbxYAfwbmiEg34KC35GCMMaHuxAlYv95Z9u6Ffftg//78P/ftgypV\noGHD/Bf/Cy6A3r3zJ4NKldz+FwW4BiEi7wPxOI9s3As8AVQFVFWnecpMBvriPNz9TlX93se+rAZh\njAkJOTmweTOsWQOrVzs/16+Hc8+FTp2cb/P16sE55zg/T70+5xyoUaPs4/n6669RVXr27HnGe6Wp\nQdiNcsYYUwhVp+nnVCJYvRq++w5iYuDii6FrV+dn585Qs2ZwY0tPT2fMmDEsWrSIGTNmcPXVZ95V\nEOpNTMYYE7JO9Qvs359/SU2Fb791EkJ29ulkMHq08/qcc9yMWfnwww958MEH+cMf/kBSUhJRUVFl\nfhyrQRhjwtqxY87wz61bTy87dpzuG/j1V6ha1bng1617uimoQQOnVtC1K8TGgpToO3hgjBw5kv/+\n979MmzaN7t27F1rWmpiMMRVaZiZs2uQseRPB1q1w6JDTN9Cy5emleXOnI/hUUqhe3e1/QfH8+OOP\ntGjRgqpVqxZZ1hKEMaZCUHXuB1i3DtauPf1z61Zo0QLats2fCFq2hEaNIKICz1ttCcIYE9Kys51v\n8r/+mn851cST93Vmpvd9nOosVoWOHaFDB2fp2NFJDOWtFuCPjIwMIiIiqFatWon3YQnCGBNwqk57\n/qkLelqa8zM9HQ4edH76en30KERGOs05p5ZTzTt51+vUce4I9qVePadGEEr9AYGyZMkS7r77bp56\n6iluueWWEu/HEoQxplhUnYt23gu9P68rV3Yu4qcu6jExzhIdDbVrOz9PLXnXIyMrdjNPcaSlpTF6\n9Gi++uorXnvtNfr371+q/dkwV2PCUHY2pKTAjz86N2X9+KOzbNvm3LVbmv2mpzt39Nate/qCn/fC\n3779mduK+nZvSkdVmT17NqNHj+bmm29mw4YN1KpVy9WYLEEYE0Cqzrfv1NTT8+wc8zHBpqrzLf1U\nQti61bkwt24N55/v/Lz2WqfjtTQX6ogI51t9OLbZl3fff/898+fP55JLLnE7FMCamIwplgMHYOVK\n+OYbZ/TMyZPeyx09ejop1KjhzLFzaomM9L3/2rWdRNC6NbRqFfw7c034sT4IY4rh6FHYuNH3N/m8\nVOGnn2DFCmdJTXXuou3e3bmJytfgkho1nEnXGjUKzNw7xvjLEoQxhdi8Gf71L2fahPXrnamWW7d2\nvq37o0kTJyH87ndO23zBKZeNKY5jx47xP//zP9x11120atUq4MezTmpjCti3D+bMgXffhZ07YdAg\nGDoU4uKcNny7yBs3LF68mHvuuYfu3btT299vKC6yGoQJC4cPO52669c7tYXly50O3VtvhV69LCEY\nd+3fv5+HHnqIZcuW8frrr9O3b9+gHdtqEKZcS0uD5GSnXyA52bnj1h8nTjj9A1u3Ov0KLVs6o32G\nDHFqD9bBa0JBZmYmXbt25cYbb2TDhg2cffbZbofkN6tBmIDYssXp1F25ElatcqZR8CYjwxkJ1KbN\n6aVOHf+OUamSM+laq1bOE7oqwt21pnxKS0ujjr+/2GXMOqlNwPz6K3zxhdOm74/du2HBAucb/eWX\nQ7ducMklzvBOb6pWdaZPsIu7MYFhCcKUqb174f33nWaa5GSIj3e+qfsjJgZ+/3u46CK76JuK58cf\nf+T8889HQuiX3xJEGFm/3rkZqyxs2gRvvAFJScX7XLVqcMMNzqifnj19j/U3xjiOHj3K448/zvvv\nv8+aNWto2rSp2yHlsk7qcuzQIfjyS0hMdL6tr1oF551XNvtu0ACef95p6inOF5pKlZzFGFO0hQsX\ncu+999KzZ082bNhA3bp13Q6pzFgNIgCOHvU9BQM43+rnzYOsLGfitUsvdW7CqlMHhg2zO2+NKQ8O\nHjzIyJEjWb16NVOnTqV3795uh+SV1SBCyKJFTvNMYc0ysbEwZYpTpm1bSwjGlEfVq1enU6dOzJgx\ngxph+kdsNYgysnQpvPUWfPopfPCBc3OWMca4zTqpy4iq0+STne39vWefhYQE75/NyoJHHoFrrnHG\n5RtjTCiwJqZiWrbM6RT2tj0hwfckbt26Oe97ezJWnTp2564x4WjlypX8/e9/Z+7cuWHblORLhUsQ\nCxdC//5w221nzsvfqhXMnAnl6E54Y0yAHD58mL/97W/MmzePSZMmcVYFfJxehUoQqvDnPztJ4Pbb\n7UYuY4x3n3zyCaNGjeKqq64iKSmJmJgYt0NyRYXpg9i4EaZPh7lznemfLTkYY7xJTExk0KBBTJ06\nlSuuuMLtcErNOqm9yMlxHhRz113OPQm7dzt9CMOGOVNBGGOML1lZWVSpUsXtMMqEdVJ77NnjPAcA\nnJrCxx87zwMYMcLZ1qmTTRthjClauCSH0gqrBDFtmjPBXNu2zvpXXzmPijTGmIIyMzNZvnw5V155\npduhhKywaGLKzHT6GDp3hmeegUcfDXJwxphyZfny5QwfPpw2bdowd+7ckJp9taxV+D6I8eNh6lS4\n+mqYMcN5xoAxxhR06NAhxo4dy4IFC3j55Ze58cYbwzo5QOkShJdbvsqWiPQVkU0isllEHvHyfqSI\nLBCRH0RkvYjcUZz9v/02TJrk3MD2zjuWHIwx3q1YsYJ27dqhqiQlJTFw4MCwTw6lFdAahIhEAJuB\nXsDPwBrgFlXdlKfMo0Ckqj4qInWBH4H6qnqywL7OqEHs2wf168OTT8Ljjwfsn2GMCQOpqals376d\nHj16uB1KUIXyKKauwBZV3QkgIh8AA4BNecooUMvzuhaQVjA5+PLoo1C3LowbV4YRG2PCUuPGjWns\n69m3xqtAJ4jGwK4867txkkZek4EFIvIzUBMY5M+Os7Kc2VPfftv73EjGmIorJyeHCLswlFoonMGr\ngURVbQRcCLwmIkVOezdrFpx7Ltx8c8DjM8aUE8ePH2f8+PHcbBeGMhHoGkQq0CzPehPPtrzuBJ4F\nUNVtIvITcAHwbcGdTZgwAYCMDHj++XgWLYqnevUARG2MKXeWLl3KiBEjaN++Pa+88orb4bgmISGB\nBF/PJSimQHdSV8LpdO4F7AFWA4NVNTlPmdeAfar6pIjUx0kMHVX1QIF95XZSv/MOvPqq8/xmG4Rg\nTMWWnp7OmDFjWLRoEZMnT+b66693O6SQErKd1KqaLSKjgMU4zVkzVDVZRO523tZpwFPA2yKyzvOx\nMQWTQ0Hffec0LVlyMMa8//77VK1alaSkJKKiotwOJ6yUyxvlGjSAxx6D++5zOShjjAlxFe5OahFI\nTYVGjVwOyhhjQlxI30ld1k6cgCpVoF49tyMxxgTTunXr+Pzzz90Oo0IpdwkiJQUaN4bKYTUPrTHG\nl4yMDB599FF69+5NWlqa2+FUKOUuQWzf7tz/YIwJf0uWLCEuLo7t27ezbt06hgwZ4nZIFUq5+x6+\nbRucd57bURhjAu3JJ59k5syZvPbaa/Tv39/tcCqkcleD2LkTmjd3OwpjTKANHjyYDRs2WHJwUbmr\nQZw4gd09bUwFcP7557sdQoVX7moQ8+ZBORmZa4zxw8mTJ8nIyHA7DONFuUsQKSnwhz+4HYUxpiwk\nJibSrVs3pk2b5nYoxotylSBUnSfG2Q1yxpRvv/32Gw8//DB9+/Zl1KhR3H///W6HZLzwK0GISFUR\naRnoYIpy8KBz/4P1QRhTfi1evJj27dvz888/s379eu644w579GeIKjJBiMjvgfXAF571TiLycaAD\n8+aFF9w4qjGmLC1dupTXXnuN9957j3o2JUJIK3IuJhH5Dme67q9U9ULPtvWqGheE+PLGoWPGKDEx\n8MgjwTyyMcaUX4GeiylLVQ8W2ObKOKLsbJvi2xhjgsWfBJEsIjcDESLSQkT+CawMcFxe7d7tzMNk\njAltWVlZPP/88yQmJrodiikFfxLEKOAiIAf4CMgEHghkUL5s327TbBgT6tasWcPFF1/Ml19+Se3a\ntd0Ox5SCP30QN6jqR0VtCzQR0Xr1lLVrnQcGGWNCy9GjRxk/fjyzZ8/mH//4B0OHDrXRSSEg0H0Q\n47xse6wkByutrCznPghjTGjJycmhR48eHDhwgA0bNnDrrbdacggDPudiEpGrgb5AYxF5Kc9bkTjN\nTUGXne3GUY0xRYmIiOCzzz6jfv36bodiylBhk/XtAzYAx4GkPNuPAGMDGZQvhw9DtWpuHNkYUxRL\nDuHHZ4JQ1UQgUUTeU9XjQYzJpwkT4Oyz3Y7CmIptx44dNGvWjIiIcjVTjykBf/6HG4vIByKyTkQ2\nn1oCHpkXlSq5cVRjDMCJEyd45pln6NKlC0lJSUV/wJR7/iSIt4G3AAH6Af8C5gQwJmNMiFm5ciUX\nXXQRy5Yt47vvviMuLqgTKRiX+JMgaqjq5wCquk1Vx+EkCmNMmMvIyOC+++7jhhtuYNy4cXz66afE\nxsa6HZYJEn+eKJcpIhHANhG5B0gFagU2LGNMKKhatSr16tVjw4YNxMTEuB2OCTJ/EsRfgLOB+4Gn\ngShgWCCDMsaEhkqVKjF+/Hi3wzAuKTJBqOoqz8sjwG0AIuLKjEh2174xxgRPoX0QInKxiFwvInU9\n6+1EZBawqrDPBcq557pxVGPCX3JyMgMGDCAtLc3tUEwI8ZkgRORZ4D1gKPCZiEwAvgLWAucHJTpj\nTEBlZmby5JNP0qNHD/r06WOT65l8CmtiGgB0VNUMEYkBdgFxqro9OKEZYwJp2bJljBgxgpYtW5KY\nmEjTpk3dDsmEmMISxHFVzQBQ1QMistmSgzHhYefOnQwePJh//vOf3HjjjTaxnvGqsARxroicmtJb\ngBZ51lHVGwIamTEmYGJjY9m6dSvVbHIzU4jCEsSNBdYnBzIQY0xwWXIwRSlssr4lwQzEH1FRbkdg\nTPmSk5PD119/TXx8vNuhmHIo4NMxikhfEdnkmeTvER9l4kUkUUQ2iMhXvvZljxs1xn9JSUlcdtll\njB8/nhMnTrgdjimHApogPFN0TAauBtoBg0XkggJlooDXgP6q2h64ydf+7GlyxhTt+PHjjB8/nvj4\neP74xz+ydOlSqtofjykBf6baAEBEqqlqZjH33xXYoqo7Pfv4AGf47KY8ZYYA81Q1FUBVf/W1M5sK\nxpjCJSUlccMNN9C+fXt++OEHGjd2ZdIDEyaKrEGISFcRWQ9s8ax3FJFX/dx/Y5z7J07Z7dmW1/lA\njIh8JSJrROQ2P/dtjCmgYcOGPP/888ybN8+Sgyk1f2oQrwD9gfkAqrpWRK4o4xg6A1fiTAr4jYh8\no6pbCxacMGFC7uv4+HjreDOmgJiYGAYMGOB2GMZFCQkJJCQklMm+RFULLyCyWlW7ikiiql7o2bZW\nVTsWuXORbsAEVe3rWR8LqKpOzFPmEaC6qj7pWZ8OLFLVeQX2pUXFakxFoqp2g5spkoigqiX6RfGn\nk3qXiHQFVEQqiciDgL+PHF0DtBSRWBGpCtwCLChQ5hPgMs++awCXAMl+7t+YCic7O5tXXnmFq666\nCvvSZALJnyamkTjNTM2AvcCXnm1FUtVsERkFLMZJRjNUNVlE7nbe1mmquklEPgfWAdnANFXdWIJ/\nizFhb926dQwfPpzq1aszbdo0q0GYgPKniSlGVQ8EKZ7C4rAmJlNhZWRk8Pe//50ZM2bwzDPPMGzY\nMCIiAn4bkwkDpWli8qcGsUZEfgTmAB+p6pGSHMgYU3Lz589n+/btrFu3jgYNGrgdjqkgiqxBAIhI\nd5z+g+uAH4APVPWDAMdWMAarQZgKyzqkTUmVpgbhV4LIc6AYYBIwVFUrleSAJWUJwhhjii+go5hE\npKaIDBWRfwOrgf1A95IczBhTuB07dvDvf//b7TCMAfwb5roB6AY8r6otVXW0qrryTGpjwtXJkyd5\n8cUX6dKlC9u323O5TGjwp5P6XFXNCXgkxlRQiYmJDB8+nKioKFauXEnLli3dDskYoJAEISIvqupo\nYJ6InNH4b0+UM6b0pk6dyuOPP87EiRO5/fbbrSPahBSfndQi0lVVV4tIL2/vB/uBQtZJbcLRtm3b\nqFWrFvXq1XM7FBOmAjqKSURGqerkorYFmiUIY4wpvkDPxTTMy7a7SnIwYyoqVeW3335zOwxjisVn\nghCRQSLyMdBCRD7Ks3wBHAxeiMaUb9u2baNPnz489dRTbodiTLEUNoppNZAGNMF5JOgpR4DEQAZl\nTDjIysripZde4oUXXmDs2LE8+OCDbodkTLH4TBCq+hPwE87srcaYYlizZg3Dhw+nXr16rF69mnPP\nPdftkIwptsJGMS1V1Z4ikg7kLSQ4U3UH9QnR1kltypOnnnqK5s2bM3ToUBu6alwVkFFMIhKhqjki\n4nXOJVXNLskBS8oShDHGFF9ARjHluXu6KVDJkxB+B9yN8+xoY4wxYcyfYa7zcR43eh7wFtAKeD+g\nURlTDqgqM2fO5Ouvv3Y7FGMCwp8EkaOqWcANwKuq+hegcWDDMia0bd68mSuvvJLXX3+d2rVrux2O\nMQHhT4I4KSI3AbcB/+fZViVwIRkTuk6cOMHTTz9N9+7dGTBgACtXrqRDhw5uh2VMQPgzm+sw4F6c\n6b63i0gLYHZgwzImNF177bVUqlSJ7777jtjYWLfDMSag/H3kaGXg1BzEW1X1ZECj8h6DjWIyrktN\nTaVRo0Y2dNWUG4GerK8H8A6QinMPRAPgNlVdXpIDlpQlCGOMKb5AJ4hvgT+q6kbPehvgHVXtUpID\nlpQlCBNMv/zyCzExMVStWtXtUIwplUDP5lr1VHIAUNVkwP5qTFjKyclh2rRpdOjQgRUrVrgdjjGu\n8qeT+nsReQN417M+FJusz4Sh5ORkRowYQVZWFkuWLCEuLs7tkIxxlT81iHuA7cAYz7Id525qY8LC\nyZMnefLJJ+nRoweDBg1i+fLllhyMoYgahIjEAecBH6vq88EJyZjgqlTJmW4sMTGRpk2buhyNMaGj\nsMn6/obz5LjvgYuBv6vqzCDGVjAe66Q2xphiCtRsrklAV1U9JiLnAAtV9eJSxFkqliCMMab4AjWK\nKVNVjwGo6v4iyhoT8lJTUxk8eDApKSluh2JMuVDYRf/cPM+h/hg4L++zqYMVoDGllZOTw5QpU+jU\nqROtW7emfv36bodkTLlQWCf1jQXWJwcyEGMCYcOGDYwYMYKIiAiWLl1K27Zt3Q7JmHLDr7mYQoH1\nQZjiSk9PJy4ujnHjxuUmCWMqmoBOtVFaItIXmITTnDVDVSf6KHcxsAIYpKpnNGFZgjAlkZGRwVln\nneV2GMa4JtBTbZSYiETgNE1dDbQDBovIBT7KPQd8Hsh4TMVjycGYkvM7QYhItRLsvyuwRVV3ep5K\n9wEwwEu5+4C5wL4SHMNUcKrKsmXL3A7DmLBTZIIQka4ish7Y4lnvKCKv+rn/xsCuPOu7KfC4UhFp\nBFyvqq/jTCdujN9SUlK49tprufvuuzl06JDb4RgTVvypQbwC9AfSAFR1LXBFGcYwCXgkz7olCVOk\n7OxsXn75ZTp37ky3bt1ITEwkKirK7bCMCSv+zOYaoao7CzxBK9vP/acCzfKsN/Fsy6sL8IE4B6gL\n9BORLFVdUHBnEyZMyH0dHx9PfHy8n2GYcJKSksJNN91E9erVWb58Oa1bt3Y7JGNCRkJCAgkJCWWy\nL38eGDQPmAi8gTMn033Apap6U5E7F6kE/Aj0AvYAq4HBnmdKeCv/FvBvG8VkCvPbb78xb948hg4d\nakNXjSlCaUYx+VODGInTzNQM2At86dlWJFXNFpFRwGJOD3NNFpG7nbd1WsGP+B25qbBq1KjBbbfd\n5nYYxoQ9u1HOhDRVpUDzpjGmGAJagxCRN/HyzV5VR5TkgMb4Q1WZPXs2U6ZMYenSpbnPbDDGBI8/\nTUxf5nldHfgD+YeuGlOmduzYwciRI0lNTWX69OmWHIxxSZE9fKo6J8/yv8ANwEWBD81UNCdPnuTF\nF1+kS5cu9OzZk++++46uXbu6HZYxFZY/NYiCWgA2X7IpcwkJCSxcuJCVK1fSsmVLt8MxpsLzZ5hr\nOqf7ICKAA8BYVf1XgGMrGId1UlcA1iltTNkK2GyunpvXmnL65rYct67SliCMMab4Ajabq+eKvFBV\nsz2LXaFNqe3fv59PPvnE7TCMMUXw5zbUH0TkwoBHYsKeqjJr1izi4uJYtWqV2+EYY4rgs5NaRCqr\n6kngQmCNiGwDjuFMpqeq2jlIMZowsG3bNu655x7S0tL49NNPuegiGwhnTKgrrAax2vPzOqA1cA1w\nEzDQ89MYv8ybN49LLrmEq6++mtWrV1tyMKac8NlJLSKJqhoyTUvWSV1+7dq1i6ysLM4991y3QzGm\nwgnIKCYR2Q285OuDqurzvUCwBGGMMcUXqLmYKgE1sQf4mGI4fvw41atXdzsMY0wZKKwG8X0odURb\nDSK07d27lwcffJAaNWowY8YMt8MxxngE6j4IqzmYIqkqM2fOJC4ujtjYWF591d/HlRtjQl1hTUy9\nghaFKZe2bNnCiBEjOHr0KIsXL6ZTp05uh2SMKUP2wCBTYi+99BIiwv33329TchsTogI2F1MosQRh\njDHFF7C5mIwxxlRcliBMkRYsWMCiRYvcDsMYE2SWIIxPe/bsYeDAgfz1r3+lZs2abodjjAkySxDm\nDDk5OUydOpUOHTpwwQUXsHbtWnr06OF2WMaYICvJI0dNmBs2bBibNm3iP//5D3FxcW6HY4xxiY1i\nMmfYtWsXjRo1sqGrxoQBG+ZqjDHGKxvmakrk0KFDHDt2zO0wjDEhyhJEBfXRRx/Rrl07G75qjPHJ\nOqkrmNTUVEaNGkVycjLvv/8+l19+udshGWNClNUgKghVZcqUKXTq1ImOHTuydu1aSw7GmEJZDaKC\nEBHS0tJYunQpbdu2dTscY0w5YKOYjDEmjNkoJmOMMWXOEkSYSU9P5+677yYpKcntUIwx5ZwliDCh\nqsyZM4d27dpRpUoVmjZt6nZIxphyLuCd1CLSF5iEk4xmqOrEAu8PAR7xrB4BRqrq+kDHFU5SUlK4\n99572bFjB3PnzqV79+5uh2SMCQMBrUGISAQwGbgaaAcMFpELChTbDlyuqh2Bp4A3AxlTuMnMzKRn\nz55ccsklfP/995YcjDFlJtA1iK7AFlXdCSAiHwADgE2nCqjqyjzlVwKNAxxTWKlWrRrr16+35zUY\nY8pcoPt7In+QAAAWOElEQVQgGgO78qzvpvAE8CfA5n4oJksOxphACJkb5UTkCuBO4DJfZSZMmJD7\nOj4+nvj4+IDHFUq+/fZbLrroIkRKNKTZGFMBJCQkkJCQUCb7CuiNciLSDZigqn0962MB9dJR3QGY\nB/RV1W0+9lVhb5RLS0vjr3/9K0uWLGHFihU0adLE7ZCMMeVEKN8otwZoKSKxIlIVuAVYkLeAiDTD\nSQ63+UoOFZWq8v7779O+fXsiIyNJSkqy5GCMCZqANjGparaIjAIWc3qYa7KI3O28rdOA8UAMMEWc\ntpMsVe0ayLjKg7S0NG699VZ+/vlnPvnkE7p2rfCnxBgTZDYXU4jKyspi5syZDBs2jCpVqrgdjjGm\nnLJHjhpjjPEqlPsgjDHGlFOWIFy2ePFiunfvzm+//eZ2KMYYk0/I3AdR0ezfv5+HHnqIZcuWMWXK\nFGrUqOF2SMYYk4/VIIJMVZk1axbt27enXr16bNiwgX79+rkdljHGnMFqEEH2ww8/8PLLL7Nw4UIu\nuugit8MxxhifbBSTC3JycoiIsMqbMSbwbBRTOWPJwRhTHtiVKkCOHj3K/Pnz3Q7DGGNKzPogAmDh\nwoXce++9XHnllQwYMMBmXy1DzZs3Z+fOnW6HYUzIiY2NZceOHWW6T+uDKEN79+7lwQcfZPXq1Uyd\nOpXevXu7HVLY8bSnuh2GMSHH19+G9UGEgISEBOLi4oiNjWX9+vWWHIwx5Z7VIMrIvn37+Pnnn+nU\nqZPboYQ1q0EY410gahCWIEy5YgnCGO+siSlEZGVluR2CMcYEnCWIYjhy5Aj3338/AwcOdDsUY0Le\nxo0bufjii90OIyxMnjyZsWPHBv24liD8tGDBAtq1a8exY8d466233A7HhKDmzZtTo0YNIiMjadSo\nEXfeeecZs/SuWLGCXr16ERkZSXR0NAMGDCA5OTlfmSNHjvDggw8SGxtLZGQkrVq14qGHHuLAgQPB\n/OeU2uOPP86YMWPcDqNUTpw4wbBhw4iKiqJRo0b885//LLT8008/TWxsLLVr12bIkCEcPXo0972H\nH36Y888/n6ioKNq2bcs777yT+15aWhqXXXYZdevWJTo6mksvvZQVK1bkvj98+HDee+89fv3117L/\nRxZGVcvF4oQafD///LMOHDhQW7Vqpf/5z39cicGc5tbvgT+aN2+e+zuyd+9e7dixo44bNy73/RUr\nVmjNmjX11Vdf1aNHj2p6erqOGzdOo6Oj9aefflJV1RMnTmiXLl30qquu0k2bNqmq6v79+/Xpp5/W\nRYsWBSz2kydPlun+9uzZo3Xq1NHMzMyQiKekxo4dq5dffrkeOnRIk5OTtUGDBvr55597Lfv2229r\nmzZtNDU1VY8dO6YDBgzQ22+/Pff9CRMm6ObNm1VVddWqVRodHa3ffPONqqoeP35cN23apNnZ2aqq\nOn/+fI2JicldV1UdMWKEvvjiiz5j9fW34dlesutuST8Y7MWtC8Obb76pf/vb3/S3335z5fgmv1BP\nEEuWLMldHzNmjPbv3z93vUePHjpq1KgzPtevX7/cC8mbb76pDRo0KNbv24YNG7RPnz4aExOjDRo0\n0GeffVZVVe+44w4dP358brmEhARt0qRJvngnTpyoHTp00OrVq+vEiRN14MCB+fZ9//336wMPPKCq\nqocOHdK77rpLGzZsqE2aNNFx48ZpTk6O15hmzZqlffr0ybftueee0/POO09r1aql7dq1048//jj3\nvbffflsvvfRS/ctf/qJ16tTJjXvGjBnapk0bjYmJ0b59++rOnTtzP/PAAw9o06ZNNTIyUrt06aL/\n/e9//T5n/mrUqJF++eWXueuPP/64Dh482GvZgQMH6gsvvJC7vmLFCj3rrLM0IyPDa/nrrrtOX3rp\npTO25+Tk6IIFCzQiIkL379+fu/29997TK6+80mesgUgQ1sRUhD/96U88/fTTnHXWWW6HYsqR3bt3\ns2jRIlq1agVARkYGK1as8Np/dfPNN/PFF18AsGTJEvr27ev379vRo0fp06cP11xzDXv27GHr1q30\n6tXLZ/mCd/V/8MEHLFq0iIMHD3LLLbewaNEijh07BjiTSn744YcMHToUgNtvv52qVauyfft2EhMT\n+eKLL5g+fbrX46xfv57WrVvn29ayZUuWL1/O4cOHeeKJJ7j11lvZu3dv7vurVq2iZcuW7Nu3j8ce\ne4xPPvmE5557jvnz57N//3569OjB4MGDc8t37dqVdevWkZ6ezpAhQ7jppps4ceKE13gmTpxIdHQ0\nMTExREdH53sdExPj9TMHDx5kz549dOjQIXdbx44dSUpK8nV688nJySEzM5MtW7ac8V5GRgZr1qyh\nXbt2+bZ37NiR6tWrc/311zN8+HDq1q2b+16bNm1Yu3atX8cuMyXNLMFeCOFvjiZ4ivo9gLJZSqJ5\n8+Zaq1YtrVWrloqI9u7dWw8dOqSqqrt371YR0R9//PGMz3322WdatWpVVVXt06ePPvroo34fc/bs\n2dq5c2ev73mrQTRt2jRfvG+//Xa+z/To0UPfeecdVVVdvHixtmzZUlVVf/nlF61WrZoeP34837Gv\nuOIKr8cePnx4kf+OTp066YIFC1TVqUHExsbme79fv346c+bM3PXs7GytUaOGpqSkeN1fdHS0rlu3\nrtBjFseuXbs0IiIiXzPZF198oS1atPBafvr06dq6dWvdsWOHHjx4UK+77jqNiIjQlStXnlH2j3/8\no15zzTVe95OZmakffPCBzpo1K9/2LVu2aOXKlX3G6+tvA6tBlN6yZcv46KOP3A7DlFJZpYiS+uST\nTzh8+DBLly5l06ZNuZ2K0dHRREREsGfPnjM+s2fPntxvinXq1PFaxpddu3Zx3nnnlTjeJk2a5Fsf\nPHgws2fPBmD27NkMGTIEgJSUFLKysmjYsGHuN+977rnHZ6dpdHQ0R44cybdt1qxZXHjhhbnf4JOS\nkvJ9vmnTpvnK79y5kwceeICYmBhiYmKoU6cOIkJqaioA//jHP2jbtm3u/g4fPlymnbg1a9YE4PDh\nw7nbDh06RK1atbyWHzZsGIMHDyY+Pp64uDiuvPJK4Mxz/PDDD7Nx40bmzJnjdT9Vq1Zl0KBBPPvs\ns6xfvz53+5EjR4iKiirVv6m4KnyCOHToECNHjmTQoEFUrmxzF5rSUU926dGjB7fffjujR48GoEaN\nGvzud7/jww8/POMz//rXv3KnZunduzeff/45GRkZfh2vadOmbNu2zet7Z599dr5RVN4ST8Emp5tu\nuomEhARSU1P5+OOPcxNE06ZNqV69OmlpaRw4cID09HQOHjzIunXrvB67Q4cObN68OXc9JSWFESNG\nMGXKFNLT00lPT6ddu3a558tbLM2aNWPq1KkcOHAg95hHjx6lW7duLFu2jBdeeIG5c+fm7i8yMjLf\n/vJ69tlnqVWrFpGRkfmWU9u8qV27Ng0bNszXrLN27dozmoXyxv/EE0/w008/kZKSQps2bWjcuDGN\nGzfOLfPEE0/w+eef88UXX+QmIF+ysrLYvn177npycjIdO3Ys9DNlrqRVj2AvBKCJad68edq4cWMd\nMWKEpqenl/n+TdkLxO9BWSnYSb1//349++yzc5s9li1bljuK6ciRI3rgwAF97LHHNDo6Wrdu3aqq\nTvNC165dtV+/frpp0ybNycnRX3/9VZ955hmvo5iOHDmijRo10pdfflkzMzP1yJEjumrVKlV1Orzb\ntGmjBw4c0D179mi3bt3OaGLKG+8p/fr10z59+pzRdHX99dfrAw88oIcPH9acnBzdtm2bLl261Ou5\n2Lt3r9atWze3eWbjxo161lln6ebNmzU7O1tnzpyplStX1hkzZqiq08TUo0ePfPv4+OOPtX379pqU\nlKSqqgcPHtQPP/xQVVUXLlyojRs31l9++UUzMzP1ySef1MqVK3v995TG2LFjNT4+XtPT03Xjxo3a\noEEDXbx4sdeyBw4c0G3btqmqalJSkrZv316nT5+e+/4zzzyjrVq10r17957x2ZUrV+qyZcv0xIkT\nmpGRoc8995xGRkbqnj17csuMGDEiXyd4Qb7+NrBRTMU3duxYbd26tc9fcBOaQjlBtGjR4owL1L33\n3ptvZNDy5cs1Pj5ea9asqVFRUdq/f3/duHFjvs8cPnxY//KXv2jTpk21Vq1a2rJlSx09erQeOHDA\n63GTkpK0V69eGh0drQ0bNtSJEyeqqjN0ctCgQRoZGakdO3bUSZMm5UsQ3uJVVX3nnXc0IiLijCGV\nhw8f1pEjR2qTJk20du3a2rlzZ50zZ47P83HzzTfne3/cuHEaExOj55xzjo4ePVrj4+MLTRCqqu++\n+67GxcVpVFSUNmvWTO+66y5Vdfojhg0bppGRkdqoUSN94YUXfP57SiMzMzP3OA0aNNBJkyble79m\nzZq6bNkyVVXdvHmztm7dWs8++2xt3rz5GWVFRKtXr661atXSmjVraq1atXJHnC1dulQ7duyokZGR\nWqdOHY2Pj8/dr6pqRkaGNmnSRPft2+cz1kAkiAo7F1NKSgr169enWrVqZbZPE3g2F1P5kZyczB13\n3MGqVavcDqXcmzx5Mrt37+a5557zWcYm6ysnsZrAsQRhjHc2WV8JHD9+PN8oBGOMMf4J6wSxdOlS\nOnXqlG/OE2OMMf4Jy3Gd6enpjBkzhs8++4xXX32V66+/3u2QjDGm3Am7GsSHH35Iu3btqFatGklJ\nSZYcjDGmhMKuBrF9+3bmzp1L9+7d3Q7FGGPKNRvFZMqV5s2bs3PnTrfDMCbkxMbGsmPHjjO2h/Qw\nVxHpC0zCac6aoaoTvZR5BegHHAPuUNUfvJSxBGGMMcUUssNcRSQCmAxcDbQDBovIBQXK9APOU9VW\nwN3AG0XtNyMjg0cffZRvvvkmAFGHvoSEBLdDCBl2Lk6zc3GanYuyEehO6q7AFlXdqapZwAfAgAJl\nBgCzAFR1FRAlIvV97XDJkiXExcWxfft2mjdvHqCwQ5v98p9m5+I0Oxen2bkoG4HupG4M7Mqzvhsn\naRRWJtWzbW+Bctx5550sWbKE1157jWuvvbasYzXGGJNHuRrFFBkZSVJSks/52I0xxpSdgHZSi0g3\nYIKq9vWsj8WZWXBinjJvAF+p6hzP+iagp6ruLbAv66E2xpgSKGkndaBrEGuAliISC+wBbgEGFyiz\nAPgzMMeTUA4WTA5Q8n+gMcaYkgloglDVbBEZBSzm9DDXZBG523lbp6nqQhG5RkS24gxzvTOQMRlj\njPFPublRzhhjTHCF3FxMItJXRDaJyGYRecRHmVdEZIuI/CAinYIdY7AUdS5EZIiIrPUsy0Qkzo04\ng8Gf3wtPuYtFJEtEbghmfMHk599IvIgkisgGEfkq2DEGix9/I5EissBzrVgvIne4EGbAicgMEdkr\nIt4fEk4Jr5slfRRdIBachLUViAWqAD8AFxQo0w/41PP6EmCl23G7eC66AVGe130r8rnIU24J8H/A\nDW7H7eLvRRSQBDT2rNd1O24Xz8WjwLOnzgOQBlR2O/YAnIvLgE7AOh/vl+i6GWo1iDK/sa4cK/Jc\nqOpKVT3kWV2Jc/9IOPLn9wLgPmAusC+YwQWZP+diCDBPVVMBVPXXIMcYLP6cCwVOjYuvBaSp6skg\nxhgUqroMSC+kSImum6GWILzdWFfwoufrxrpw48+5yOtPwKKARuSeIs+FiDQCrlfV14FwHvHmz+/F\n+UCMiHwlImtE5LagRRdc/pyLyUBbEfkZWAs8EKTYQk2Jrpvl6kY5452IXIEz+usyt2Nx0SQgbxt0\nOCeJolQGOgNXAmcD34jIN6q61d2wXHE1kKiqV4rIecAXItJBVY+6HVh5EGoJIhVolme9iWdbwTJN\niygTDvw5F4hIB2Aa0FdVC6tilmf+nIsuwAciIjhtzf1EJEtVFwQpxmDx51zsBn5V1ePAcRH5GuiI\n014fTvw5F3cCzwKo6jYR+Qm4APg2KBGGjhJdN0OtiSn3xjoRqYpzY13BP/AFwB8h905trzfWhYEi\nz4WINAPmAbep6jYXYgyWIs+Fqp7rWVrg9EPcG4bJAfz7G/kEuExEKolIDZxOyeQgxxkM/pyLnUBv\nAE+b+/nA9qBGGTyC75pzia6bIVWDULuxLpc/5wIYD8QAUzzfnLNUteBkiOWen+ci30eCHmSQ+Pk3\nsklEPgfWAdnANFXd6GLYAeHn78VTwNt5hn+OUdUDLoUcMCLyPhAP1BGRFOAJoCqlvG7ajXLGGGO8\nCrUmJmOMMSHCEoQxxhivLEEYY4zxyhKEMcYYryxBGGOM8coShDHGGK8sQZiQISLZIvK9Z5rq7z03\nAvoqGysi68vgmF95pov+QUT+KyKtSrCPu0XkVs/r20WkQZ73ponIBWUc5yrPHfRFfeYBEale2mOb\nissShAklx1S1s6pe6PmZUkT5srqJZ7CqdsKZ7fIfxf2wqk5V1Xc9q3eQZxI0VR2hqpvKJMrTcb6O\nf3E+CNQoo2ObCsgShAklZ0wT4KkpfC0i33qWbl7KtPV8q/7e8w37PM/2oXm2v+6527yw434NnPps\nL8/n1orIdBGp4tn+nOchPD+IyPOebU+IyGgRuRFnTqh3PZ+t7vnm39lTy3g+T8y3i8grJYzzG6BR\nnn1NEZHV4jwQ5wnPtvs8Zb4SkSWebVeJyArPeZzjmYbDGJ8sQZhQclaeJqZ5nm17gd6q2gVnrp1X\nvXzuHmCSqnbGuUDv9jTrDAK6e7bnAEOLOP51wHoRqQa8Bdykqh1xHkYzUkRicKYUb+/5Jv9Uns+q\nqs7DmQRuiKcGdDzP+/OAP+RZH4QzuWBJ4uwLzM+z/jfPFCsdgXgRaa+qr+JMxhavqr1EpA7wGNDL\ncy6/A0YXcRxTwYXUXEymwvvNc5HMqyowWZxHJGYD3voIvgEeE5GmwEequlVEeuFMeb3G8428Ok6y\n8eY9EckAduA8dKg1sD3PBIj/C9wLvAZkiMh04FOcJ9d5c0YNQFV/FZFtItIVZ1bV1qq6QkT+XMw4\nq+FM4Z33kZG3iMhwnL/nBkBbYAP5J2/r5tm+3HOcKjjnzRifLEGYUPcX4BdV7SAilYCMggVUdbaI\nrAT6A596JmsT4H9V9TE/jjFEVRNPrXi+bXu7yGd7LvC9gJuAUZ7X/pqDU1vYBHx86nDFjdPTVDUZ\nuFFEmuPUBC5S1cMi8hZOkilIgMWqWlTtxJhc1sRkQom3tvcoYI/n9R+BSmd8SKSFqv7kaVZZAHTA\neTb1QBE5x1MmupBRUQWP+yMQKyLnetZvA5Z62uxrq+pnwEOe4xR0BIj0cZyPcR79eAvO4zEpYZyP\nA5eIyPmeYx0FjogznXW/POUP54llJXBpnv6ZGiUZsWUqFksQJpR4G5U0BbhDRBJx5vI/5qXMzZ6O\n40SgHTBLVZOBccBiEVmLMyV0Ay+fPeOYqpqJMx3yXM9ns4E3cC62/+fZ9jVO7aagt4E3TnVS592/\nqh7EeS5DM1X91rOt2HF6+jZeBB5W1XXAD579vgssy/OZN4HPRGSJ57nUdwKzPcdZgdOUZoxPNt23\nMcYYr6wGYYwxxitLEMYYY7yyBGGMMcYrSxDGGGO8sgRhjDHGK0sQxhhjvLIEYYwxxitLEMYYY7z6\nf7cYSH+9Q/YFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119fc9dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(target_test, rf.predict_proba(features_test)[:,1]) \n",
    "    \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print 'ROC AUC: %0.3f' % roc_auc\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Random Forest does the best, but I still am not getting the accurancy on my target class of interest. I have a few tricks I can do to work on this, but that is for another day/class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear SVM with L2 penalty, Cost function of 1 and auto class weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.86      1.00      0.92      1708\n",
      "        Yes       1.00      0.01      0.02       292\n",
      "\n",
      "avg / total       0.88      0.86      0.79      2000\n",
      "\n",
      "[[1708    0]\n",
      " [ 289    3]]\n",
      "0.8555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_linSVC=LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, class_weight='balanced')\n",
    "clf_linSVC.fit(features_train, target_train)\n",
    "predicted_SVC=clf_linSVC.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVC,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVC))\n",
    "print accuracy_score(expected,predicted_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SVC kernel= linear\n",
    "#Change Class_Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.86      1.00      0.92      1708\n",
      "        Yes       1.00      0.01      0.02       292\n",
      "\n",
      "avg / total       0.88      0.86      0.79      2000\n",
      "\n",
      "[[1708    0]\n",
      " [ 289    3]]\n",
      "0.8555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=1.0,class_weight=None,gamma=0.1)\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.96      0.74      0.84      1708\n",
      "        Yes       0.35      0.80      0.49       292\n",
      "\n",
      "avg / total       0.87      0.75      0.79      2000\n",
      "\n",
      "[[1271  437]\n",
      " [  57  235]]\n",
      "0.753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=1.0,class_weight='balanced',gamma='auto')\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search of Cost Function (with cross validation)\n",
    "# This takes a long time to run. So skip unless you have the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [mean: 0.86167, std: 0.00000, params: {'C': 0.01}, mean: 0.86167, std: 0.00000, params: {'C': 0.05}, mean: 0.86200, std: 0.00067, params: {'C': 1}, mean: 0.87167, std: 0.00350, params: {'C': 5}, mean: 0.87300, std: 0.00386, params: {'C': 10}, mean: 0.87133, std: 0.00542, params: {'C': 15}]\n",
      "BEST SCORE 0.873\n",
      "BEST PARAM {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "parameters = {'C':[.01,.05,1,5,10,15]}\n",
    "svr = SVC(kernel='linear')\n",
    "grid_svm = GridSearchCV(svr, parameters,n_jobs=-1, cv=5)\n",
    "grid_svm.fit(features_train, target_train)\n",
    "print \"SCORES\", grid_svm.grid_scores_\n",
    "print \"BEST SCORE\", grid_svm.best_score_\n",
    "print \"BEST PARAM\", grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Grid Search of Several Functions (with cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#How does \"Best\" perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.95      0.71      0.82      1708\n",
      "        Yes       0.32      0.79      0.46       292\n",
      "\n",
      "avg / total       0.86      0.73      0.76      2000\n",
      "\n",
      "[[1221  487]\n",
      " [  62  230]]\n",
      "0.7255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=10.0,class_weight='balanced',gamma='auto')\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using a RBF (non-linear) Kernel (High dimensional Space). Untuned.\n",
    "Not shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using Polynominal Kernel (2nd Degree), untuned.\n",
    "Would not fit at 2nd and 3rd degree given 24 hours\n",
    "NOT SHOWN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_poly = SVC(kernel='poly', degree=2, C=1.0,class_weight=None)\n",
    "clf_poly.fit(features_train, target_train)\n",
    "predicted_poly=clf_poly.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_poly,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_poly))\n",
    "print accuracy_score(expected,predicted_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.92      0.95      0.93      1708\n",
      "        Yes       0.64      0.50      0.56       292\n",
      "\n",
      "avg / total       0.88      0.89      0.88      2000\n",
      "\n",
      "[[1624   84]\n",
      " [ 145  147]]\n",
      "0.8855\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boost Classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf_GBC = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "clf_GBC.fit(features_train, target_train)\n",
    "predicted_GBC=clf_GBC.predict(features_test)\n",
    "expected = target_test\n",
    "print(classification_report(expected, predicted_GBC,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_GBC))\n",
    "print accuracy_score(expected,predicted_GBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.96      0.98      0.97      1708\n",
      "        Yes       0.88      0.73      0.80       292\n",
      "\n",
      "avg / total       0.95      0.95      0.94      2000\n",
      "\n",
      "[[1680   28]\n",
      " [  78  214]]\n",
      "0.947\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost of a Decision Tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)\n",
    "bdt.fit(features_train, target_train)\n",
    "predicted_bdt=bdt.predict(features_test)\n",
    "expected = target_test\n",
    "print(classification_report(expected, predicted_bdt,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_bdt))\n",
    "print accuracy_score(expected,predicted_bdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.91608392  0.919       0.90690691]\n",
      "0.913996940997\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.95      0.96      0.96      1708\n",
      "        Yes       0.74      0.73      0.74       292\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2000\n",
      "\n",
      "[[1634   74]\n",
      " [  79  213]]\n",
      "0.9235\n"
     ]
    }
   ],
   "source": [
    "#Extra Trees- Extremely Random Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "xtree = DecisionTreeClassifier(max_depth=None, min_samples_split=1,\n",
    "random_state=0)\n",
    "xtree.fit(features_train, target_train)\n",
    "predicted_xtree=xtree.predict(features_test)\n",
    "scores_xtree=cross_val_score(xtree, features_train, target_train,n_jobs=-1)\n",
    "print scores_xtree\n",
    "print scores_xtree.mean() \n",
    "print(classification_report(expected, predicted_xtree,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_xtree))\n",
    "print accuracy_score(expected,predicted_xtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.94605395  0.942       0.94694695]\n",
      "0.945000297667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.95      0.99      0.97      1708\n",
      "        Yes       0.91      0.71      0.80       292\n",
      "\n",
      "avg / total       0.95      0.95      0.94      2000\n",
      "\n",
      "[[1688   20]\n",
      " [  85  207]]\n",
      "0.9475\n"
     ]
    }
   ],
   "source": [
    "#Standard Bagging Classifier\n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "#as with all models, there are lots of arguments to adjust\n",
    "bag=BaggingClassifier(base_estimator=None, n_estimators=10, max_samples=1.0, \n",
    "                      max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, \n",
    "                      warm_start=False, n_jobs=-1, random_state=None, verbose=0)\n",
    "bag.fit(features_train, target_train)\n",
    "predicted_bag=bag.predict(features_test)\n",
    "scores_bag = cross_val_score(bag, features_train, target_train)\n",
    "print scores_bag\n",
    "print scores_bag.mean()\n",
    "print(classification_report(expected, predicted_bag,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_bag))\n",
    "print accuracy_score(expected,predicted_bag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88311688  0.882       0.86286286]\n",
      "0.87599324866\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.91      0.95      0.93      1708\n",
      "        Yes       0.64      0.46      0.54       292\n",
      "\n",
      "avg / total       0.87      0.88      0.88      2000\n",
      "\n",
      "[[1631   77]\n",
      " [ 157  135]]\n",
      "0.883\n"
     ]
    }
   ],
   "source": [
    "#Adaboost Only\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "ada.fit(features_train, target_train)\n",
    "predicted_ada=ada.predict(features_test)\n",
    "scores_ada = cross_val_score(ada, features_train, target_train)\n",
    "print scores_ada\n",
    "print scores_ada.mean()\n",
    "print(classification_report(expected, predicted_ada,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_ada))\n",
    "print accuracy_score(expected,predicted_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7972028   0.822       0.75875876]\n",
      "0.792653851987\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.85      1.00      0.92      1708\n",
      "        Yes       0.20      0.00      0.01       292\n",
      "\n",
      "avg / total       0.76      0.85      0.79      2000\n",
      "\n",
      "[[1704    4]\n",
      " [ 291    1]]\n",
      "0.8525\n"
     ]
    }
   ],
   "source": [
    "#Stocastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#as with all models, there are lots of arguments to adjust\n",
    "SGD=SGDClassifier(alpha=0.0001, average=False, class_weight='balanced', epsilon=0.1,\n",
    "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
    "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=-1,\n",
    "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
    "       verbose=0, warm_start=False)\n",
    "SGD.fit(features_train, target_train)\n",
    "predicted_SGD=SGD.predict(features_test)\n",
    "scores_SGD = cross_val_score(SGD, features_train, target_train)\n",
    "print scores_SGD\n",
    "print scores_SGD.mean()\n",
    "print(classification_report(expected, predicted_SGD,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SGD))\n",
    "print accuracy_score(expected,predicted_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87 (+/- 0.01) [Logistic Regression]\n",
      "Accuracy: 0.93 (+/- 0.01) [Random Forest]\n",
      "Accuracy: 0.59 (+/- 0.07) [naive Bayes]\n",
      "Accuracy: 0.90 (+/- 0.01) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "#Majority Voting\n",
    "#A form of Stacking\n",
    "#Note you don't have to put in the packages each time, only once per session\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "#Three Models Log Reg, RF and NB\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "\n",
    "for MV, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "\n",
    "    scores = cross_validation.cross_val_score(MV, features_train, target_train, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0, 1] or [-1, +1], or standardize it to have mean 0 and variance 1. Note that you must apply the same scaling to the test set for meaningful results. You can use StandardScaler for standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(features_train)  \n",
    "features_train = scaler.transform(features_train)  \n",
    "# apply same transformation to test data\n",
    "features_test = scaler.transform(features_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# two hidden layers (5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.93      0.91      0.92      1708\n",
      "        Yes       0.54      0.61      0.57       292\n",
      "\n",
      "avg / total       0.87      0.87      0.87      2000\n",
      "\n",
      "[[1554  154]\n",
      " [ 114  178]]\n",
      "0.866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "MLP1 = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                   hidden_layer_sizes=(5, 2), random_state=1, max_iter=2000)\n",
    "MLP1.fit(features_train, target_train)   \n",
    "predicted_MLP1=MLP1.predict(features_test)\n",
    "expected = target_test\n",
    "print MLP1\n",
    "print(classification_report(expected, predicted_MLP1,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_MLP1))\n",
    "print accuracy_score(expected,predicted_MLP1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# one hidden layer (15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(15,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.92      0.93      0.93      1708\n",
      "        Yes       0.58      0.53      0.55       292\n",
      "\n",
      "avg / total       0.87      0.88      0.87      2000\n",
      "\n",
      "[[1595  113]\n",
      " [ 137  155]]\n",
      "0.875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "MLP2 = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                   hidden_layer_sizes=(15,), random_state=1, max_iter=2000)\n",
    "MLP2.fit(features_train, target_train)   \n",
    "predicted_MLP2=MLP2.predict(features_test)\n",
    "expected = target_test\n",
    "print MLP2\n",
    "print(classification_report(expected, predicted_MLP2,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_MLP2))\n",
    "print accuracy_score(expected,predicted_MLP2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change solver and alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ML3P' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-4f6c448ebeba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                    hidden_layer_sizes=(15,), random_state=1, max_iter=2000)\n\u001b[1;32m      4\u001b[0m \u001b[0mMLP3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredicted_MLP3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mML3P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mMLP3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ML3P' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "MLP3 = MLPClassifier(solver='sgd', alpha=.1,\n",
    "                   hidden_layer_sizes=(15,), random_state=1, max_iter=2000)\n",
    "MLP3.fit(features_train, target_train)   \n",
    "predicted_MLP3=MLP3.predict(features_test)\n",
    "expected = target_test\n",
    "print MLP3\n",
    "print(classification_report(expected, predicted_MLP3,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_MLP3))\n",
    "print accuracy_score(expected,predicted_MLP3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
