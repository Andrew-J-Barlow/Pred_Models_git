<<<<<<< HEAD
plot(usconsumption, ylab="% change in consumption and income",
plot.type="single", col=1:2, xlab="Year")
legend("topright", legend=c("Consumption","Income"),
lty=1, col=c(1,2), cex=.9)
plot(consumption ~ income, data=usconsumption,
ylab="% change in consumption", xlab="% change in income")
abline(fit.ex3)
summary(fit.ex3)
fcast <- forecast(fit.ex3, newdata = data.frame(income = c(-1, 1)))
par(mfrow = c(1, 1))
plot(fcast, ylab = "% change in consumption", xlab = "% change in income")
fit.ex4 <- tslm(austa ~ trend)
f <- forecast(fit.ex4, h = 5, level = c(80, 95))
plot(f, ylab = "International tourist arrivals to Australia (millions)",
xlab = "t")
lines(fit.ex4$fitted, col = "blue")
summary(fit.ex4)
par(mfrow=c(2,2))
res3 <- ts(resid(fit.ex3), s = 1970.25, f = 4)
plot.ts(res3, ylab = "res (Consumption)")
abline(0, 0)
Acf(res3)
res4 <- resid(fit.ex4)
plot(res4, ylab = "res (Tourism)")
abline(0, 0)
Acf(res4)
nf <- layout(matrix(c(1, 2, 3, 3), 2, 2, byrow = TRUE))
plot(ausair, ylab = "Air Passengers in Australia (millions)", xlab = "Year")
plot(guinearice, ylab = "Rice Production in Guinea (million tons) ",
xlab = "Year")
plot(c(guinearice), c(ausair),
xlab = "Rice Production in Guinea (million tons)",
ylab = "Air Passengers in Australia (millions)")
summary(lm(ausair ~ guinearice))
plot(usconsumption, xlab="Year",
main="Quarterly changes in US consumption and personal income")
summary(lm(ausair ~ guinearice))
plot(ausair, ylab = "Air Passengers in Australia (millions)", xlab = "Year")
plot(guinearice, ylab = "Rice Production in Guinea (million tons) ",
xlab = "Year")
plot(c(guinearice), c(ausair),
xlab = "Rice Production in Guinea (million tons)",
ylab = "Air Passengers in Australia (millions)")
summary(lm(ausair ~ guinearice))
data(airmiles)
plot(log(airmiles),ylab='Log(airmiles)',xlab='Year', main='')
acf(diff(diff(window(log(airmiles),end=c(2001,8)),12)),lag.max=48,main='')
air.m1=arimax(log(airmiles),order=c(0,1,1),seasonal=list(order=c(0,1,1),
period=12),xtransf=data.frame(I911=1*(seq(airmiles)==69),
I911=1*(seq(airmiles)==69)),
transfer=list(c(0,0),c(1,0)),xreg=data.frame(Dec96=1*(seq(airmiles)==12),
Jan97=1*(seq(airmiles)==13),Dec02=1*(seq(airmiles)==84)),method='ML')
install.packages("TSA")
library(TSA)
data(airmiles)
plot(log(airmiles),ylab='Log(airmiles)',xlab='Year', main='')
acf(diff(diff(window(log(airmiles),end=c(2001,8)),12)),lag.max=48,main='')
air.m1=arimax(log(airmiles),order=c(0,1,1),seasonal=list(order=c(0,1,1),
period=12),xtransf=data.frame(I911=1*(seq(airmiles)==69),
I911=1*(seq(airmiles)==69)),
transfer=list(c(0,0),c(1,0)),xreg=data.frame(Dec96=1*(seq(airmiles)==12),
Jan97=1*(seq(airmiles)==13),Dec02=1*(seq(airmiles)==84)),method='ML')
library(forecast)
library(fpp)
# Example 4.3. US consumption expenditure
fit.ex3 <- lm(consumption ~ income, data=usconsumption)
par(mfrow=c(1,2))
plot(usconsumption, ylab="% change in consumption and income",
plot.type="single", col=1:2, xlab="Year")
legend("topright", legend=c("Consumption","Income"),
lty=1, col=c(1,2), cex=.9)
plot(consumption ~ income, data=usconsumption,
ylab="% change in consumption", xlab="% change in income")
abline(fit.ex3)
summary(fit.ex3)
fcast <- forecast(fit.ex3, newdata = data.frame(income = c(-1, 1)))
par(mfrow = c(1, 1))
plot(fcast, ylab = "% change in consumption", xlab = "% change in income")
# Example 4.4 Linear trend
fit.ex4 <- tslm(austa ~ trend)
f <- forecast(fit.ex4, h = 5, level = c(80, 95))
plot(f, ylab = "International tourist arrivals to Australia (millions)",
xlab = "t")
lines(fit.ex4$fitted, col = "blue")
summary(fit.ex4)
par(mfrow=c(2,2))
res3 <- ts(resid(fit.ex3), s = 1970.25, f = 4)
plot.ts(res3, ylab = "res (Consumption)")
abline(0, 0)
Acf(res3)
res4 <- resid(fit.ex4)
plot(res4, ylab = "res (Tourism)")
abline(0, 0)
Acf(res4)
# Spurious regression
nf <- layout(matrix(c(1, 2, 3, 3), 2, 2, byrow = TRUE))
plot(ausair, ylab = "Air Passengers in Australia (millions)", xlab = "Year")
plot(guinearice, ylab = "Rice Production in Guinea (million tons) ",
xlab = "Year")
plot(c(guinearice), c(ausair),
xlab = "Rice Production in Guinea (million tons)",
ylab = "Air Passengers in Australia (millions)")
summary(lm(ausair ~ guinearice))
#US expenditures
plot(usconsumption, xlab="Year",
main="Quarterly changes in US consumption and personal income")
fit <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(2,0,0))
tsdisplay(arima.errors(fit), main="ARIMA errors")
(fit2 <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(1,0,2)))
Box.test(residuals(fit2),fitdf=5,lag=10,type="Ljung")
fcast <- forecast(fit2,xreg=rep(mean(usconsumption[,2]),8), h=8)
plot(fcast, main="Forecasts from regression with ARIMA(1,0,2) errors")
fit <- auto.arima(usconsumption[,1], xreg=usconsumption[,2])
# Example 9.2. International visitors to Australia
plot(austa, xlab = "Year", ylab = "millions of people",
main = "Total annual international visitors to Australia")
(auto.arima(austa, d = 0, xreg = 1:length(austa)))
(auto.arima(austa, d = 1))
fit1 <- Arima(austa, order = c(0, 1, 0), include.drift = TRUE)
fit2 <- Arima(austa, order = c(2, 0, 0), include.drift = TRUE)
par(mfrow = c(2,1))
plot(forecast(fit2),
main = "Forecasts from linear trend + AR(2) error", ylim = c(1, 8))
plot(forecast(fit1), ylim = c(1, 8))
# Example 9.3 TV advertising and insurance quotations
plot(insurance, main="Insurance advertising and quotations", xlab="Year")
# Lagged predictors. Test 0, 1, 2 or 3 lags.
Advert <- cbind(insurance[,2],
c(NA,insurance[1:39,2]),
c(NA,NA,insurance[1:38,2]),
c(NA,NA,NA,insurance[1:37,2]))
colnames(Advert) <- paste("AdLag",0:3,sep="")
# Choose optimal lag length for advertising based on AIC
# Restrict data so models use same fitting period
fit1 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1], d=0)
fit2 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:2], d=0)
fit3 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:3], d=0)
fit4 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:4], d=0)
# Best model fitted to all data (based on AICc)
# Refit using all data
fit <- auto.arima(insurance[,1], xreg=Advert[,1:2], d=0)
fit
fc8 <- forecast(fit, xreg=cbind(c(Advert[40,1],rep(8,19)),rep(8,20)), h=20)
par(mfrow = c(1,1))
plot(fc8, main="Forecast quotes with advertising set to 8", ylab="Quotes")
# Lagged predictors. Test 0, 1, 2 or 3 lags.
Advert <- cbind(insurance[,2],
c(NA,insurance[1:39,2]),
c(NA,NA,insurance[1:38,2]),
c(NA,NA,NA,insurance[1:37,2]))
colnames(Advert) <- paste("AdLag",0:3,sep="")
# Choose optimal lag length for advertising based on AIC
# Restrict data so models use same fitting period
fit1 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1], d=0)
fit2 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:2], d=0)
fit3 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:3], d=0)
fit4 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:4], d=0)
fit1
fit2
fit3
fit4
# Best model fitted to all data (based on AICc)
# Refit using all data
fit <- auto.arima(insurance[,1], xreg=Advert[,1:2], d=0)
fit
fc8 <- forecast(fit, xreg=cbind(c(Advert[40,1],rep(8,19)),rep(8,20)), h=20)
par(mfrow = c(1,1))
plot(fc8, main="Forecast quotes with advertising set to 8", ylab="Quotes")
#US expenditures
plot(usconsumption, xlab="Year",
main="Quarterly changes in US consumption and personal income")
fit <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(2,0,0))
tsdisplay(arima.errors(fit), main="ARIMA errors")
(fit2 <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(1,0,2)))
Box.test(residuals(fit2),fitdf=5,lag=10,type="Ljung")
fcast <- forecast(fit2,xreg=rep(mean(usconsumption[,2]),8), h=8)
plot(fcast, main="Forecasts from regression with ARIMA(1,0,2) errors")
fit <- auto.arima(usconsumption[,1], xreg=usconsumption[,2])
plot(fit)
#US expenditures
plot(usconsumption, xlab="Year",
main="Quarterly changes in US consumption and personal income")
fit <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(2,0,0))
tsdisplay(arima.errors(fit), main="ARIMA errors")
(fit2 <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(1,0,2)))
Box.test(residuals(fit2),fitdf=5,lag=10,type="Ljung")
fcast <- forecast(fit2,xreg=rep(mean(usconsumption[,2]),8), h=8)
plot(fcast, main="Forecasts from regression with ARIMA(1,0,2) errors")
plot(fit <- auto.arima(usconsumption[,1], xreg=usconsumption[,2])
#US expenditures
plot(usconsumption, xlab="Year",
main="Quarterly changes in US consumption and personal income")
fit <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(2,0,0))
tsdisplay(arima.errors(fit), main="ARIMA errors")
(fit2 <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(1,0,2)))
Box.test(residuals(fit2),fitdf=5,lag=10,type="Ljung")
fcast <- forecast(fit2,xreg=rep(mean(usconsumption[,2]),8), h=8)
plot(fcast, main="Forecasts from regression with ARIMA(1,0,2) errors")
plot(fit <- auto.arima(usconsumption[,1], xreg=usconsumption[,2]))
#US expenditures
plot(usconsumption, xlab="Year",
main="Quarterly changes in US consumption and personal income")
fit <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(2,0,0))
tsdisplay(arima.errors(fit), main="ARIMA errors")
(fit2 <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(1,0,2)))
Box.test(residuals(fit2),fitdf=5,lag=10,type="Ljung")
fcast <- forecast(fit2,xreg=rep(mean(usconsumption[,2]),8), h=8)
plot(fcast, main="Forecasts from regression with ARIMA(1,0,2) errors")
acf(fit <- auto.arima(usconsumption[,1], xreg=usconsumption[,2]))
# Example 9.2. International visitors to Australia
plot(austa, xlab = "Year", ylab = "millions of people",
main = "Total annual international visitors to Australia")
(auto.arima(austa, d = 0, xreg = 1:length(austa)))
(auto.arima(austa, d = 1))
fit1 <- Arima(austa, order = c(0, 1, 0), include.drift = TRUE)
fit2 <- Arima(austa, order = c(2, 0, 0), include.drift = TRUE)
par(mfrow = c(2,1))
plot(forecast(fit2),
main = "Forecasts from linear trend + AR(2) error", ylim = c(1, 8))
plot(forecast(fit1), ylim = c(1, 8))
# Example 9.3 TV advertising and insurance quotations
plot(insurance, main="Insurance advertising and quotations", xlab="Year")
# Lagged predictors. Test 0, 1, 2 or 3 lags.
Advert <- cbind(insurance[,2],
c(NA,insurance[1:39,2]),
c(NA,NA,insurance[1:38,2]),
c(NA,NA,NA,insurance[1:37,2]))
colnames(Advert) <- paste("AdLag",0:3,sep="")
# Choose optimal lag length for advertising based on AIC
# Restrict data so models use same fitting period
fit1 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1], d=0)
fit2 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:2], d=0)
fit3 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:3], d=0)
fit4 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:4], d=0)
fit1
fit2
fit3
fit4
# Best model fitted to all data (based on AICc), which was the xreg=Advert[4:40,1:2], d=0
# Refit using all data
fit <- auto.arima(insurance[,1], xreg=Advert[,1:2], d=0)
fit
fc8 <- forecast(fit, xreg=cbind(c(Advert[40,1],rep(8,19)),rep(8,20)), h=20)
par(mfrow = c(1,1))
plot(fc8, main="Forecast quotes with advertising set to 8", ylab="Quotes")
# Example 9.3 TV advertising and insurance quotations
plot(insurance, main="Insurance advertising and quotations", xlab="Year")
# Lagged predictors. Test 0, 1, 2 or 3 lags.
Advert <- cbind(insurance[,2],
c(NA,insurance[1:39,2]),
c(NA,NA,insurance[1:38,2]),
c(NA,NA,NA,insurance[1:37,2]))
colnames(Advert) <- paste("AdLag",0:3,sep="")
# Choose optimal lag length for advertising based on AIC
# Restrict data so models use same fitting period
it1 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1], d=0)
fit2 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:2], d=0)
fit3 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:3], d=0)
fit4 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:4], d=0)
fit1f
# Example 9.3 TV advertising and insurance quotations
plot(insurance, main="Insurance advertising and quotations", xlab="Year")
# Lagged predictors. Test 0, 1, 2 or 3 lags.
Advert <- cbind(insurance[,2],
c(NA,insurance[1:39,2]),
c(NA,NA,insurance[1:38,2]),
c(NA,NA,NA,insurance[1:37,2]))
colnames(Advert) <- paste("AdLag",0:3,sep="")
# Choose optimal lag length for advertising based on AIC
# Restrict data so models use same fitting period
it1 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1], d=0)
fit2 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:2], d=0)
fit3 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:3], d=0)
fit4 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:4], d=0)
fit1
fit2
fit3
fit4
# Best model fitted to all data (based on AICc), which was the xreg=Advert[4:40,1:2], d=0
# Refit using all data
fit <- auto.arima(insurance[,1], xreg=Advert[,1:2], d=0)
fit
fc8 <- forecast(fit, xreg=cbind(c(Advert[40,1],rep(8,19)),rep(8,20)), h=20)
par(mfrow = c(1,1))
plot(fc8, main="Forecast quotes with advertising set to 8", ylab="Quotes")
# Example 9.3 TV advertising and insurance quotations
plot(insurance, main="Insurance advertising and quotations", xlab="Year")
# Lagged predictors. Test 0, 1, 2 or 3 lags.
Advert <- cbind(insurance[,2],
c(NA,insurance[1:39,2]),
c(NA,NA,insurance[1:38,2]),
c(NA,NA,NA,insurance[1:37,2]))
colnames(Advert) <- paste("AdLag",0:3,sep="")
# Choose optimal lag length for advertising based on AIC
# Restrict data so models use same fitting period
fit1 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1], d=0)
fit2 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:2], d=0)
fit3 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:3], d=0)
fit4 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:4], d=0)
fit1
fit2
fit3
fit4
# Best model fitted to all data (based on AICc), which was the xreg=Advert[4:40,1:2], d=0
# Refit using all data
fit <- auto.arima(insurance[,1], xreg=Advert[,1:2], d=0)
fit
fc8 <- forecast(fit, xreg=cbind(c(Advert[40,1],rep(8,19)),rep(8,20)), h=20)
par(mfrow = c(1,1))
plot(fc8, main="Forecast quotes with advertising set to 8", ylab="Quotes")
install.packages("rstanarm")
library(rstanarm)
op <- options(contrasts = c("contr.helmert", "contr.poly"))
stan_aov(yield ~ block + N*P*K, data = npk,
prior = R2(0.5), seed = 12345)
options(op)
(fit <- stan_lm(mpg ~ wt + qsec + am, data = mtcars, prior = R2(0.75),
# the next line is only to make the example go fast enough
chains = 1, iter = 500, seed = 12345))
plot(fit, prob = 0.8)y
plot(fit, "hist", pars = c("wt", "am", "qsec", "sigma"),
transformations = list(sigma = "log"))
plot(fit, prob = 0.8)
plot(fit, "hist", pars = c("wt", "am", "qsec", "sigma"),
transformations = list(sigma = "log"))
#US expenditures
plot(usconsumption, xlab="Year",
main="Quarterly changes in US consumption and personal income")
library(forecast)
library(fpp)
# Example 4.3. US consumption expenditure
#LM Regression with Forecasting
fit.ex3 <- lm(consumption ~ income, data=usconsumption)
par(mfrow=c(1,2))
plot(usconsumption, ylab="% change in consumption and income",
plot.type="single", col=1:2, xlab="Year")
legend("topright", legend=c("Consumption","Income"),
lty=1, col=c(1,2), cex=.9)
plot(consumption ~ income, data=usconsumption,
ylab="% change in consumption", xlab="% change in income")
abline(fit.ex3)
summary(fit.ex3)
fcast <- forecast(fit.ex3, newdata = data.frame(income = c(-1, 1)))
par(mfrow = c(1, 1))
plot(fcast, ylab = "% change in consumption", xlab = "% change in income")
# Example 4.4 Linear trend
fit.ex4 <- tslm(austa ~ trend)
f <- forecast(fit.ex4, h = 5, level = c(80, 95))
plot(f, ylab = "International tourist arrivals to Australia (millions)",
xlab = "t")
lines(fit.ex4$fitted, col = "blue")
summary(fit.ex4)
par(mfrow=c(2,2))
res3 <- ts(resid(fit.ex3), s = 1970.25, f = 4)
plot.ts(res3, ylab = "res (Consumption)")
abline(0, 0)
Acf(res3)
res4 <- resid(fit.ex4)
plot(res4, ylab = "res (Tourism)")
abline(0, 0)
Acf(res4)
# Spurious regression
nf <- layout(matrix(c(1, 2, 3, 3), 2, 2, byrow = TRUE))
plot(ausair, ylab = "Air Passengers in Australia (millions)", xlab = "Year")
plot(guinearice, ylab = "Rice Production in Guinea (million tons) ",
xlab = "Year")
plot(c(guinearice), c(ausair),
xlab = "Rice Production in Guinea (million tons)",
ylab = "Air Passengers in Australia (millions)")
summary(lm(ausair ~ guinearice))
#US expenditures
plot(usconsumption, xlab="Year",
main="Quarterly changes in US consumption and personal income")
fit <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(2,0,0))
tsdisplay(arima.errors(fit), main="ARIMA errors")
(fit2 <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(1,0,2)))
Box.test(residuals(fit2),fitdf=5,lag=10,type="Ljung")
fcast <- forecast(fit2,xreg=rep(mean(usconsumption[,2]),8), h=8)
plot(fcast, main="Forecasts from regression with ARIMA(1,0,2) errors")
fit <- auto.arima(usconsumption[,1], xreg=usconsumption[,2])
#US expenditures
plot(usconsumption, xlab="Year",
main="Quarterly changes in US consumption and personal income")
fit <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(2,0,0))
tsdisplay(arima.errors(fit), main="ARIMA errors")
(fit2 <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(1,0,2)))
Box.test(residuals(fit2),fitdf=5,lag=10,type="Ljung")
residuals.Arima(fit2, type='regression')
#US expenditures
plot(usconsumption, xlab="Year",
main="Quarterly changes in US consumption and personal income")
fit <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(2,0,0))
tsdisplay(arima.errors(fit), main="ARIMA errors")
(fit2 <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(1,0,2)))
#Box.test(residuals(fit2),fitdf=5,lag=10,type="Ljung")
residuals.Arima(fit2, type='regression')
(fit2 <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(1,0,2)))
#US expenditures
plot(usconsumption, xlab="Year",
main="Quarterly changes in US consumption and personal income")
fit <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(2,0,0))
tsdisplay(arima.errors(fit), type='regression',main="ARIMA errors")
install.packages(c("checkmate", "curl", "data.table", "gapminder", "glue", "irlba", "ISLR", "lazyeval", "lubridate", "purrr", "quantmod", "quantreg", "Rcmdr", "RcppArmadillo", "tidyr", "tidyselect"))
#US expenditures
plot(usconsumption, xlab="Year",
main="Quarterly changes in US consumption and personal income")
fit <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(2,0,0))
tsdisplay(residuals.Arima(fit), main="ARIMA errors")
#US expenditures
plot(usconsumption, xlab="Year",
main="Quarterly changes in US consumption and personal income")
fit <- Arima(usconsumption[,1], xreg=usconsumption[,2],
order=c(2,0,0))
tsdisplay(residuals.Arima(fit), main="ARIMA errors")
#A continuous Target
setwd('/Users/mylesgartland/OneDrive - Rockhurst University/Courses/Predictive Models/Pred_Models_git/Week 5/data')
=======
y<-mu+z
# display the first five (x,y) pairs (no assignment), with
# y-values rounded to 3 decimal places
cbind(x[1:5],round(y[1:5],3))
# draw a scatterplot of x against y
plot(x,y)
# customize the scatterplot using optional arguments to the
# plot() function
plot(x,y,pch=19,col="red",cex=0.5,main="plot of x vs y")
plot(rexp(100),rexp(100), ylab="Y Axis", xlab = "X Axis")
plot(runif(100),rnorm(100), ylab="Y Axis", xlab = "X Axis")
install.packages(c("backports", "chron", "Rcpp", "rprojroot", "tseries"))
library(haven)
mobi <- read_sav("~/Documents/Creighton/DBA 820/mobi.sav")
View(mobi)
library(haven)
Album_Sales <- read_sav("~/Documents/Creighton/DBA 821/Field Data/Album Sales.sav")
View(Album_Sales)
lm(Album_Sales$Sales~.)
lm(Album_Sales$Sales~., data=Album_Sales)
Sales<-lm(Album_Sales$Sales~., data=Album_Sales)
summary(Sales)
plot(Sales)
Sales<-lm(Album_Sales$Sales~., data=Album_Sales)
summary(Sales)
plot(Sales)
summary(Sales)
plot(Sales)
install.packages(c("data.table", "digest", "e1071", "fma", "Matrix", "mgcv", "nlme", "RcppArmadillo"))
install.packages("plotly")
library(plotly)
g <- ggplot(faithful, aes(x = eruptions, y = waiting)) +
stat_density_2d(aes(fill = ..level..), geom = "polygon") +
xlim(1, 6) + ylim(40, 100)
ggplotly(g)
plot_ly(z = ~volcano, type = "surface")
faithful
install.packages(c("rpart.plot", "stringr"))
library('ggmap')
library("ggplot2")
library('ggraph')
library('ggrepel')
qmap(location = "boston university",zoom = 17)
qmap(location = "boston university",zoom = 17, maptype = "hybrid")
qmap(location = "Rockhurst university")
qmap(location = "Rockhurst university", zoom=16)
qmap(location = "Rockhurst university", zoom=18)
qmap(location = "Rockhurst university", zoom=20)
qmap(location = "Rockhurst university", zoom=19)
qmap(location = "Rockhurst university", zoom=19, maptype='hybrid')
qmap(location="12710 S. Hagan, 66062")
qmap(location="12710 S. Hagan, 66062", maptype='hybird', zoom=17)
qmap(location="12710 S. Hagan, 66062", maptype='hybrid', zoom=17)
qmap(location="12710 S. Hagan, 66062", maptype='hybrid', zoom=20)
install.packages('dplyr')
library(dplyr)
install.packages("dplyr")
install.packages("dplyr")
crime
library(dplyr)
crime
violent_crimes <- filter(crime,
offense != "auto theft", offense != "theft", offense != "burglary"
)
install.packages('dplyr')
install.packages("dplyr")
library(dplyr)
violent_crimes <- filter(crime,
offense != "auto theft", offense != "theft", offense != "burglary"
)
violent_crimes <- filter(crime,
offense != "auto theft", offense != "theft", offense != "burglary"
)
us <- c(left = -125, bottom = 25.75, right = -67, top = 49)
map <- get_stamenmap(us, zoom = 5, maptype = "toner-lite")
ggmap(map)
library('ggmap')
library("ggplot2")
library('ggraph')
library('ggrepel')
violent_crimes <- filter(crime,
offense != "auto theft", offense != "theft", offense != "burglary"
)
View(violent_crimes)
violent_crimes$offense <- factor(
violent_crimes$offense,
levels = c("robbery", "aggravated assault", "rape", "murder")
)
violent_crimes <- filter(violent_crimes,
-95.39681 <= lon & lon <= -95.34188,
29.73631 <= lat & lat <=  29.78400
)
qmplot(lon, lat, data = violent_crimes, maptype = "toner-lite", color = I("red"))
robberies <- violent_crimes %>% filter(offense == "robbery")
qmplot(lon, lat, data = violent_crimes, geom = "blank", zoom = 15, maptype = "toner-background", darken = .7, legend = "topleft") +
stat_density_2d(aes(fill = ..level..), geom = "polygon", alpha = .3, color = NA) +
scale_fill_gradient2("Robbery\nPropensity", low = "white", mid = "yellow", high = "red", midpoint = 650)
qmplot(lon, lat, data = violent_crimes, maptype = "toner-background", color = offense) +
facet_wrap(~ offense)
install.packages("gcookbook")
library(gcookbook) # For the data set
library(igraph)
madmen2
g <- graph.data.frame(madmen2, directed=TRUE)
par(mar=c(0,0,0,0))
#first plot
plot(g, layout=layout.fruchterman.reingold, vertex.size=8, edge.arrow.size=0.5,
vertex.label=NA)
library(igraph)
library(gcookbook) # For the data set
# Copy madmen and drop every other row
m <- madmen[1:nrow(madmen) %% 2 == 1, ]
g <- graph.data.frame(m, directed=FALSE)
# Print out the names of each vertex
V(g)$name
plot(g, layout=layout.fruchterman.reingold,  #l.f.r is a popular SN algorythym
vertex.size        = 4,          # Smaller nodes
vertex.label       = V(g)$name,  # Set the labels
vertex.label.cex   = 0.8,        # Slightly smaller font
vertex.label.dist  = 0.4,        # Offset the labels
vertex.label.color = "black")
# change the appearance
g$layout <- layout.fruchterman.reingold  #l.f.r is a popular SN algorythym
plot(g)
# View the edges
E(g)
# Set some of the labels to "M"
E(g)[c(2,11,19)]$label <- "M"
# Set color of all to grey, and then color a few red
E(g)$color             <- "grey70"
E(g)[c(2,11,19)]$color <- "red"
plot(g)
install.packages('network')
nflo<-network(flo)
#Display the network, indicating degree and flagging the Medicis
plot(nflo, displaylabels=TRUE,vertex.cex=apply(flo,2,sum)+1, usearrows=FALSE,
vertex.sides=3+apply(flo,2,sum),
vertex.col=2+(network.vertex.names(nflo)=="Medici"))
data(flo)
nflo<-network(flo)
#Display the network, indicating degree and flagging the Medicis
plot(nflo, displaylabels=TRUE,vertex.cex=apply(flo,2,sum)+1, usearrows=FALSE,
vertex.sides=3+apply(flo,2,sum),
vertex.col=2+(network.vertex.names(nflo)=="Medici"))
data(flo)
nflo<-network(flo)
#Display the network, indicating degree and flagging the Medicis
plot(nflo, displaylabels=TRUE,vertex.cex=apply(flo,2,sum)+1, usearrows=FALSE,
vertex.sides=3+apply(flo,2,sum),
vertex.col=2+(network.vertex.names(nflo)=="Medici"))
library(network)
data(flo)
nflo<-network(flo)
#Display the network, indicating degree and flagging the Medicis
plot(nflo, displaylabels=TRUE,vertex.cex=apply(flo,2,sum)+1, usearrows=FALSE,
vertex.sides=3+apply(flo,2,sum),
vertex.col=2+(network.vertex.names(nflo)=="Medici"))
install.packages(c("chron", "forecast", "ggplot2", "tseries"))
library(ggplot2)
set.seed(10)
df.rnorm <- data.frame(rnorm = rnorm(10000, mean = 5))
ggplot(data = df.rnorm, aes(x = rnorm)) +
geom_histogram(bins = 50) +
geom_vline(xintercept = 5, color = "red", linetype = "dashed")
library(ggplot2)
set.seed(10)
df.rnorm <- data.frame(rnorm = rnorm(10000, mean = 5))
ggplot(data = df.rnorm, aes(x = rnorm)) +
geom_histogram(bins = 50) +
geom_vline(xintercept = 5, color = "red", linetype = "dashed")
ggplot(data = df.rnorm, aes(x = rnorm)) +
geom_histogram(bins = 50) +
geom_vline(xintercept = 5, color = "blue", linetype = "dashed")
ggplot(data = df.rnorm, aes(x = rnorm)) +
geom_histogram(bins = 50) +
geom_vline(xintercept = 5, color = "orange", linetype = "dashed")
ggplot(data = df.rnorm, aes(x = rnorm)) +
geom_histogram(bins = 50) +
geom_vline(xintercept = 5, color = "orange", linetype = "soild")
ggplot(data = df.rnorm, aes(x = rnorm)) +
geom_histogram(bins = 50) +
geom_vline(xintercept = 5, color = "orange", linetype = "solid")
install.packages("glmnet")
longley<-data(longley)
longley
longley
library("glmnet", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
longley<-data(longley)
install.packages("AppliedPredictiveModeling")
data(solubility)
library("AppliedPredictiveModeling", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
data(solubility)
View(solTestXtrans)
View(solTestX)
col(solTestX)
summary(solTestX)
rbind(solTestXtrans,solTrainXtrans)
sol<-rbind(solTestXtrans,solTrainXtrans)
y<-rbind(solTestY,solTrainY)
y<-cbind(solTestY,solTrainY)
y<-data.frame(rbind(solTestY,solTrainY))
solTestY<-data.frame(solTestY)
solTrainY<-data.frame(solTrainY)
sol<-rbind(solTestXtrans,solTrainXtrans)
View(y)
View(y)
y<-data.frame(cbind(solTestY,solTrainY))
View(sol)
View(solTrainY)
colnames(solTestY) <- c("Y")
colnames(solTrainY) <- c("Y")
sol<-rbind(solTestXtrans,solTrainXtrans)
View(solTestY)
View(solTrainY)
y<-data.frame(rbind(solTestY,solTrainY))
solubility<-cbind(y,sol)
View(solubility)
write.csv(solubility, file="solubility.csv")
2+2
y<-5
y
y+2
y<--5
y
y+2
z<-rnorm(100)
z
martha<-rnorm(100)
martha
summary(martha)
hist(martha)
boxplot(martha)
hist(martha,col='red')
pep<-rexp(100)
plot(martha,pep)
data(state)
state77 <- as.data.frame(state.x77)
View(state77)
summary(Population)
li
install.packages("googleVis")
library(googleVis)
demo(WorldBank) ## At least version googleVis_0.2.10 required
AndrewMap <- gvisMap(Andrew, "LatLong" , "Tip",
options=list(showTip=TRUE,
showLine=TRUE,
enableScrollWheel=TRUE,
mapType='terrain',
useMapTypeControl=TRUE))
Andrew
plot(AndrewMap)
library(plotly)
set.seed(100)
d <- diamonds[sample(nrow(diamonds), 1000), ]
d
plot_ly(d, x = ~carat, y = ~price, color = ~carat,
size = ~carat, text = ~paste("Clarity: ", clarity))
names(state77)[4] <- "Life.Exp"
names(state77)[6] <- "HS.Grad"
model <- lm(Life.Exp ~ ., data=state77) #the '.' means include 'all' the remaining variables
summary(model) #shows the summary of the MRLM
plot(model)
plot(model)
install.packages(c("cluster", "CORElearn", "curl", "DBI", "forecast", "ggraph", "jsonlite", "lattice", "mclust", "mvtnorm", "pbkrtest", "Rcpp", "RcppEigen", "readr", "rmarkdown", "SparseM", "stringi", "survival", "tibble", "units", "viridisLite"))
install.packages(c("devtools", "dplyr", "gdata", "jsonlite"))
install.packages(c("dplyr", "glue"))
install.packages(c("bindrcpp", "DBI", "R6"))
install.packages("tidyverse")
install.packages(c("foreign", "glue"))
#A continuous Target
setwd('/Users/mpgartland/Documents/Courses/Predictive Models/Pred_Models_git/Week 5/data')
>>>>>>> 3d58ec91039a81c3192d990fcf6fa9be263961e4
## Step 2: Exploring and preparing the data ----
# read in data and examine structure
concrete <- read.csv("concrete.csv")
str(concrete)
#custom normalization function
#This is called min/max normalization (vs z-score)
#Normalization by Scaling Between 0 and 1
#Common way for ANN
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
# apply min/max normalization to entire data frame
#note all values are now between 0 and 1
concrete_norm <- as.data.frame(lapply(concrete, normalize))
boxplot(concrete_norm)
# confirm that the range is now between zero and one
summary(concrete_norm$strength)
# compared to the original minimum and maximum
summary(concrete$strength)
# create training and test data
#Split the dataset into a training and testing sets 70/30
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]
## Step 3: Training a model on the data ----
# train the neuralnet model
library(neuralnet)
# simple ANN with only a two hidden neurons
concrete_model_1 <- neuralnet(formula = strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = 2, algorithm = "rprop+", learningrate=NULL)
#rprop+ is a backpropagation method called resilient backpropagation. It modifies
#its learning rate on the error.
# visualize the network topology
#note one node in the hidden layer
plot(concrete_model_1)
#table of nuerons and weights
concrete_model_1$result.matrix
## Step 4: Evaluating model performance ----
# obtain model results
model_results_1 <- compute(concrete_model_1, concrete_test[1:8]) #You are running the training set through the ANN model
# obtain predicted strength values
predicted_strength_1 <- model_results_1$net.result #The prediction of each observation
# examine the correlation between predicted and actual values
cor(predicted_strength_1, concrete_test$strength)
#RMSE
sqrt(mean((concrete_test$strength-predicted_strength_1)^2))
## Step 5: Improving model performance ----
# a more complex neural network topology with 5 hidden neurons
concrete_model2 <- neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = 5,algorithm = "rprop+", learningrate=NULL)
# plot the network
#note 5 neurons in the hidden layer
plot(concrete_model2)
# evaluate the results as we did before
model_results2 <- compute(concrete_model2, concrete_test[1:8])
predicted_strength2 <- model_results2$net.result
cor(predicted_strength2, concrete_test$strength)
predicted_strength2[1:10]
#what do you notice about the values?
#Return norm value to a regular value
denormalize <- function(x) {
return(x*(max(concrete$strength)) - min(concrete$strength))+min(concrete$strength)
}
#look at predicted vs actual
accuracy<-data.frame(denormalize(predicted_strength2),concrete$strength[774:1030])
#plot pred vs actual
plot(denormalize(predicted_strength2),concrete$strength[774:1030])
#Model with two hidden layers
concrete_model3 <- neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = c(5,3), algorithm = "rprop+", learningrate=NULL)
plot(concrete_model3)
<<<<<<< HEAD
plot(concrete_model3)
=======
## R code 8.2
library(rethinking)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
#Set Data to me mapped
data(rugged)
d <- rugged
d$log_gdp <- log(d$rgdppc_2000)
dd <- d[ complete.cases(d$rgdppc_2000) , ]
## R code 8.3
#Create a function for the PD from this data set given
#the below regression
m8.1 <- map(
alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa ,
a ~ dnorm(0,100),
bR ~ dnorm(0,10),
bA ~ dnorm(0,10),
bAR ~ dnorm(0,10),
sigma ~ dunif(0,10)
) ,
data=dd )
#Review Model
precis(m8.1)
plot(m8.1$bR)
## R code 8.4
#Simplify the data set
dd.trim <- dd[ , c("log_gdp","rugged","cont_africa") ]
str(dd.trim)
## R code 8.5
#Remap (to STAN) the regression function
#sigma to a uniform prior
#using a Hamiltonian MCMC to sample from the PD
m8.1stan <- map2stan(
alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa ,
a ~ dnorm(0,100),
bR ~ dnorm(0,10),
bA ~ dnorm(0,10),
bAR ~ dnorm(0,10),
sigma ~ dcauchy(0,2)
) ,
data=dd.trim,iter=2000,warmup = 1000 )
#View MCMC model via STAN
print(m8.1stan)
## R code 8.6
#Updated Regression output
precis(m8.1stan)
## R code 8.7
#Using 4 Chains
m8.1stan_4chains <- map2stan( m8.1stan , chains=4 , cores=4 )
precis(m8.1stan_4chains)
## R code 8.8
#extact sampled values
post <- extract.samples( m8.1stan )
str(post)
## R code 8.9
pairs(post)
#PD of each parameter
dens(post$a)
dens(post$bR)
## R code 8.10
pairs(m8.1stan)
## R code 8.11
show(m8.1stan)
## R code 8.12
plot(m8.1stan)
#########################
#Additional code)
#########################
## R code 8.13
y <- c(-1,1)
m8.2 <- map2stan(
alist(
y ~ dnorm( mu , sigma ) ,
mu <- alpha
) ,
data=list(y=y) , start=list(alpha=0,sigma=1) ,
chains=2 , iter=4000 , warmup=1000 )
## R code 8.14
precis(m8.2)
## R code 8.15
m8.3 <- map2stan(
alist(
y ~ dnorm( mu , sigma ) ,
mu <- alpha ,
alpha ~ dnorm( 1 , 10 ) ,
sigma ~ dcauchy( 0 , 1 )
) ,
data=list(y=y) , start=list(alpha=0,sigma=1) ,
chains=2 , iter=4000 , warmup=1000 )
precis(m8.3)
## R code 8.16
y <- rcauchy(1e4,0,5)
mu <- sapply( 1:length(y) , function(i) sum(y[1:i])/i )
plot(mu,type="l")
## R code 8.17
y <- rnorm( 100 , mean=0 , sd=1 )
## R code 8.18
m8.4 <- map2stan(
alist(
y ~ dnorm( mu , sigma ) ,
mu <- a1 + a2 ,
sigma ~ dcauchy( 0 , 1 )
) ,
data=list(y=y) , start=list(a1=0,a2=0,sigma=1) ,
chains=2 , iter=4000 , warmup=1000 )
precis(m8.4)
## R code 8.19
m8.5 <- map2stan(
alist(
y ~ dnorm( mu , sigma ) ,
mu <- a1 + a2 ,
a1 ~ dnorm( 0 , 10 ) ,
a2 ~ dnorm( 0 , 10 ) ,
sigma ~ dcauchy( 0 , 1 )
) ,
data=list(y=y) , start=list(a1=0,a2=0,sigma=1) ,
chains=2 , iter=4000 , warmup=1000 )
precis(m8.5)
## R code 8.20
mp <- map2stan(
alist(
a ~ dnorm(0,1),
b ~ dcauchy(0,1)
),
data=list(y=1),
start=list(a=0,b=0),
iter=1e4, warmup=100 , WAIC=FALSE )
## R code 8.21
N <- 100                          # number of individuals
height <- rnorm(N,10,2)           # sim total height of each
leg_prop <- runif(N,0.4,0.5)      # leg as proportion of height
leg_left <- leg_prop*height +     # sim left leg as proportion + error
rnorm( N , 0 , 0.02 )
leg_right <- leg_prop*height +    # sim right leg as proportion + error
rnorm( N , 0 , 0.02 )
# combine into data frame
d <- data.frame(height,leg_left,leg_right)
## R code 8.22
m5.8s <- map2stan(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + bl*leg_left + br*leg_right ,
a ~ dnorm( 10 , 100 ) ,
bl ~ dnorm( 2 , 10 ) ,
br ~ dnorm( 2 , 10 ) ,
sigma ~ dcauchy( 0 , 1 )
) ,
data=d, chains=4,
start=list(a=10,bl=0,br=0,sigma=1) )
## R code 8.23
m5.8s2 <- map2stan(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + bl*leg_left + br*leg_right ,
a ~ dnorm( 10 , 100 ) ,
bl ~ dnorm( 2 , 10 ) ,
br ~ dnorm( 2 , 10 ) & T[0,] ,
sigma ~ dcauchy( 0 , 1 )
) ,
data=d, chains=4,
start=list(a=10,bl=0,br=0,sigma=1) )
>>>>>>> 3d58ec91039a81c3192d990fcf6fa9be263961e4
