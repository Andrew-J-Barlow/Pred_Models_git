{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Classification Methods, SVMs, Tuning and CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like R, Python uses packages in data mining/machine learning. The 3 mose common ones are Pandas (manipulation), Scikit Learn (machine learning) and Matplotlit (graphics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mpgartland1/Documents/Documents/Courses/Predictive Models/Week 3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add packages\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "from sklearn import tree \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import scipy.stats as ss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import time\n",
    "from operator import itemgetter\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mpgartland1/Documents/Documents/Courses/Data Mining/Week 5\n"
     ]
    }
   ],
   "source": [
    "cd '/Users/mpgartland1/Documents/Documents/Courses/Data Mining/Week 5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Read in Data\n",
    "#Churn Calls Data\n",
    "This is a Pandas operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>1</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>175.2</td>\n",
       "      <td>74</td>\n",
       "      <td>29.78</td>\n",
       "      <td>151.7</td>\n",
       "      <td>79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>230.5</td>\n",
       "      <td>109</td>\n",
       "      <td>10.37</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>146.3</td>\n",
       "      <td>128</td>\n",
       "      <td>24.87</td>\n",
       "      <td>162.5</td>\n",
       "      <td>80</td>\n",
       "      <td>13.81</td>\n",
       "      <td>129.3</td>\n",
       "      <td>109</td>\n",
       "      <td>5.82</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>19</td>\n",
       "      <td>171.9</td>\n",
       "      <td>96</td>\n",
       "      <td>29.22</td>\n",
       "      <td>198.4</td>\n",
       "      <td>111</td>\n",
       "      <td>16.86</td>\n",
       "      <td>321.7</td>\n",
       "      <td>76</td>\n",
       "      <td>14.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>41</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>159.3</td>\n",
       "      <td>66</td>\n",
       "      <td>27.08</td>\n",
       "      <td>125.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.70</td>\n",
       "      <td>261.9</td>\n",
       "      <td>76</td>\n",
       "      <td>11.79</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>42</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>129</td>\n",
       "      <td>29.07</td>\n",
       "      <td>183.9</td>\n",
       "      <td>96</td>\n",
       "      <td>15.63</td>\n",
       "      <td>130.2</td>\n",
       "      <td>90</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AK</td>\n",
       "      <td>48</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>37</td>\n",
       "      <td>211.7</td>\n",
       "      <td>115</td>\n",
       "      <td>35.99</td>\n",
       "      <td>159.9</td>\n",
       "      <td>84</td>\n",
       "      <td>13.59</td>\n",
       "      <td>144.1</td>\n",
       "      <td>80</td>\n",
       "      <td>6.48</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AK</td>\n",
       "      <td>50</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>183.6</td>\n",
       "      <td>107</td>\n",
       "      <td>31.21</td>\n",
       "      <td>58.6</td>\n",
       "      <td>118</td>\n",
       "      <td>4.98</td>\n",
       "      <td>202.6</td>\n",
       "      <td>99</td>\n",
       "      <td>9.12</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AK</td>\n",
       "      <td>51</td>\n",
       "      <td>area_code_510</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>12</td>\n",
       "      <td>135.8</td>\n",
       "      <td>60</td>\n",
       "      <td>23.09</td>\n",
       "      <td>200.6</td>\n",
       "      <td>134</td>\n",
       "      <td>17.05</td>\n",
       "      <td>192.4</td>\n",
       "      <td>98</td>\n",
       "      <td>8.66</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>104</td>\n",
       "      <td>36.89</td>\n",
       "      <td>152.3</td>\n",
       "      <td>83</td>\n",
       "      <td>12.95</td>\n",
       "      <td>134.3</td>\n",
       "      <td>109</td>\n",
       "      <td>6.04</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>170.9</td>\n",
       "      <td>71</td>\n",
       "      <td>29.05</td>\n",
       "      <td>201.4</td>\n",
       "      <td>80</td>\n",
       "      <td>17.12</td>\n",
       "      <td>159.0</td>\n",
       "      <td>124</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account_length      area_code international_plan voice_mail_plan  \\\n",
       "0    AK               1  area_code_408                 no              no   \n",
       "1    AK              36  area_code_408                 no             yes   \n",
       "2    AK              36  area_code_415                yes             yes   \n",
       "3    AK              41  area_code_415                 no              no   \n",
       "4    AK              42  area_code_415                 no              no   \n",
       "5    AK              48  area_code_415                 no             yes   \n",
       "6    AK              50  area_code_408                 no              no   \n",
       "7    AK              51  area_code_510                yes             yes   \n",
       "8    AK              52  area_code_408                 no              no   \n",
       "9    AK              52  area_code_415                 no             yes   \n",
       "\n",
       "   number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "0                      0              175.2               74   \n",
       "1                     30              146.3              128   \n",
       "2                     19              171.9               96   \n",
       "3                      0              159.3               66   \n",
       "4                      0              171.0              129   \n",
       "5                     37              211.7              115   \n",
       "6                      0              183.6              107   \n",
       "7                     12              135.8               60   \n",
       "8                      0              217.0              104   \n",
       "9                     24              170.9               71   \n",
       "\n",
       "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "0             29.78              151.7               79             12.89   \n",
       "1             24.87              162.5               80             13.81   \n",
       "2             29.22              198.4              111             16.86   \n",
       "3             27.08              125.9               75             10.70   \n",
       "4             29.07              183.9               96             15.63   \n",
       "5             35.99              159.9               84             13.59   \n",
       "6             31.21               58.6              118              4.98   \n",
       "7             23.09              200.6              134             17.05   \n",
       "8             36.89              152.3               83             12.95   \n",
       "9             29.05              201.4               80             17.12   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                230.5                109               10.37   \n",
       "1                129.3                109                5.82   \n",
       "2                321.7                 76               14.48   \n",
       "3                261.9                 76               11.79   \n",
       "4                130.2                 90                5.86   \n",
       "5                144.1                 80                6.48   \n",
       "6                202.6                 99                9.12   \n",
       "7                192.4                 98                8.66   \n",
       "8                134.3                109                6.04   \n",
       "9                159.0                124                7.15   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                 5.3                 3               1.43   \n",
       "1                14.5                 6               3.92   \n",
       "2                10.5                 1               2.84   \n",
       "3                11.1                 5               3.00   \n",
       "4                 4.6                 6               1.24   \n",
       "5                12.2                 1               3.29   \n",
       "6                 8.7                 3               2.35   \n",
       "7                12.3                 7               3.32   \n",
       "8                11.8                 4               3.19   \n",
       "9                 4.1                 5               1.11   \n",
       "\n",
       "   number_customer_service_calls churn  \n",
       "0                              1    no  \n",
       "1                              0    no  \n",
       "2                              1   yes  \n",
       "3                              1    no  \n",
       "4                              0    no  \n",
       "5                              1    no  \n",
       "6                              1    no  \n",
       "7                              2    no  \n",
       "8                              2    no  \n",
       "9                              2    no  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv(\"Churn_Calls.csv\", sep=',')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'state', u'account_length', u'area_code', u'international_plan',\n",
      "       u'voice_mail_plan', u'number_vmail_messages', u'total_day_minutes',\n",
      "       u'total_day_calls', u'total_day_charge', u'total_eve_minutes',\n",
      "       u'total_eve_calls', u'total_eve_charge', u'total_night_minutes',\n",
      "       u'total_night_calls', u'total_night_charge', u'total_intl_minutes',\n",
      "       u'total_intl_calls', u'total_intl_charge',\n",
      "       u'number_customer_service_calls', u'churn'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# See each collum name\n",
    "print df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Target\n",
    "In this step I took the target variable and moved it to the first collum. I aslo made a reference to it called targetName. This just helps me with some below steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn</th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>1</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>175.2</td>\n",
       "      <td>74</td>\n",
       "      <td>29.78</td>\n",
       "      <td>151.7</td>\n",
       "      <td>79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>230.5</td>\n",
       "      <td>109</td>\n",
       "      <td>10.37</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>146.3</td>\n",
       "      <td>128</td>\n",
       "      <td>24.87</td>\n",
       "      <td>162.5</td>\n",
       "      <td>80</td>\n",
       "      <td>13.81</td>\n",
       "      <td>129.3</td>\n",
       "      <td>109</td>\n",
       "      <td>5.82</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>19</td>\n",
       "      <td>171.9</td>\n",
       "      <td>96</td>\n",
       "      <td>29.22</td>\n",
       "      <td>198.4</td>\n",
       "      <td>111</td>\n",
       "      <td>16.86</td>\n",
       "      <td>321.7</td>\n",
       "      <td>76</td>\n",
       "      <td>14.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>41</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>159.3</td>\n",
       "      <td>66</td>\n",
       "      <td>27.08</td>\n",
       "      <td>125.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.70</td>\n",
       "      <td>261.9</td>\n",
       "      <td>76</td>\n",
       "      <td>11.79</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>42</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>129</td>\n",
       "      <td>29.07</td>\n",
       "      <td>183.9</td>\n",
       "      <td>96</td>\n",
       "      <td>15.63</td>\n",
       "      <td>130.2</td>\n",
       "      <td>90</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>48</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>37</td>\n",
       "      <td>211.7</td>\n",
       "      <td>115</td>\n",
       "      <td>35.99</td>\n",
       "      <td>159.9</td>\n",
       "      <td>84</td>\n",
       "      <td>13.59</td>\n",
       "      <td>144.1</td>\n",
       "      <td>80</td>\n",
       "      <td>6.48</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>50</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>183.6</td>\n",
       "      <td>107</td>\n",
       "      <td>31.21</td>\n",
       "      <td>58.6</td>\n",
       "      <td>118</td>\n",
       "      <td>4.98</td>\n",
       "      <td>202.6</td>\n",
       "      <td>99</td>\n",
       "      <td>9.12</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>51</td>\n",
       "      <td>area_code_510</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>12</td>\n",
       "      <td>135.8</td>\n",
       "      <td>60</td>\n",
       "      <td>23.09</td>\n",
       "      <td>200.6</td>\n",
       "      <td>134</td>\n",
       "      <td>17.05</td>\n",
       "      <td>192.4</td>\n",
       "      <td>98</td>\n",
       "      <td>8.66</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>104</td>\n",
       "      <td>36.89</td>\n",
       "      <td>152.3</td>\n",
       "      <td>83</td>\n",
       "      <td>12.95</td>\n",
       "      <td>134.3</td>\n",
       "      <td>109</td>\n",
       "      <td>6.04</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>170.9</td>\n",
       "      <td>71</td>\n",
       "      <td>29.05</td>\n",
       "      <td>201.4</td>\n",
       "      <td>80</td>\n",
       "      <td>17.12</td>\n",
       "      <td>159.0</td>\n",
       "      <td>124</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  churn state  account_length      area_code international_plan  \\\n",
       "0    no    AK               1  area_code_408                 no   \n",
       "1    no    AK              36  area_code_408                 no   \n",
       "2   yes    AK              36  area_code_415                yes   \n",
       "3    no    AK              41  area_code_415                 no   \n",
       "4    no    AK              42  area_code_415                 no   \n",
       "5    no    AK              48  area_code_415                 no   \n",
       "6    no    AK              50  area_code_408                 no   \n",
       "7    no    AK              51  area_code_510                yes   \n",
       "8    no    AK              52  area_code_408                 no   \n",
       "9    no    AK              52  area_code_415                 no   \n",
       "\n",
       "  voice_mail_plan  number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "0              no                      0              175.2               74   \n",
       "1             yes                     30              146.3              128   \n",
       "2             yes                     19              171.9               96   \n",
       "3              no                      0              159.3               66   \n",
       "4              no                      0              171.0              129   \n",
       "5             yes                     37              211.7              115   \n",
       "6              no                      0              183.6              107   \n",
       "7             yes                     12              135.8               60   \n",
       "8              no                      0              217.0              104   \n",
       "9             yes                     24              170.9               71   \n",
       "\n",
       "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "0             29.78              151.7               79             12.89   \n",
       "1             24.87              162.5               80             13.81   \n",
       "2             29.22              198.4              111             16.86   \n",
       "3             27.08              125.9               75             10.70   \n",
       "4             29.07              183.9               96             15.63   \n",
       "5             35.99              159.9               84             13.59   \n",
       "6             31.21               58.6              118              4.98   \n",
       "7             23.09              200.6              134             17.05   \n",
       "8             36.89              152.3               83             12.95   \n",
       "9             29.05              201.4               80             17.12   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                230.5                109               10.37   \n",
       "1                129.3                109                5.82   \n",
       "2                321.7                 76               14.48   \n",
       "3                261.9                 76               11.79   \n",
       "4                130.2                 90                5.86   \n",
       "5                144.1                 80                6.48   \n",
       "6                202.6                 99                9.12   \n",
       "7                192.4                 98                8.66   \n",
       "8                134.3                109                6.04   \n",
       "9                159.0                124                7.15   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                 5.3                 3               1.43   \n",
       "1                14.5                 6               3.92   \n",
       "2                10.5                 1               2.84   \n",
       "3                11.1                 5               3.00   \n",
       "4                 4.6                 6               1.24   \n",
       "5                12.2                 1               3.29   \n",
       "6                 8.7                 3               2.35   \n",
       "7                12.3                 7               3.32   \n",
       "8                11.8                 4               3.19   \n",
       "9                 4.1                 5               1.11   \n",
       "\n",
       "   number_customer_service_calls  \n",
       "0                              1  \n",
       "1                              0  \n",
       "2                              1  \n",
       "3                              1  \n",
       "4                              0  \n",
       "5                              1  \n",
       "6                              1  \n",
       "7                              2  \n",
       "8                              2  \n",
       "9                              2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# designate target variable name\n",
    "targetName = 'churn'\n",
    "# move target variable into first column\n",
    "targetSeries = df[targetName]\n",
    "del df[targetName]\n",
    "df.insert(0, targetName, targetSeries)\n",
    "expected=targetName\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#EDA\n",
    "Just a touch of EDA. This is the distribution of the target. As you can see, the datset is imbalanced and the target class of interest \"yes\" is in the minority (a common occurance in classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x10b11de90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEWCAYAAACDoeeyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH8atWzStYm/gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b11dbd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gb = df.groupby(targetName)\n",
    "targetEDA=gb[targetName].aggregate(len)\n",
    "plt.figure()\n",
    "targetEDA.plot(kind='bar', grid=False)\n",
    "plt.axhline(0, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Preprocessing\n",
    "The below two steps are for preprocessing. The first cell changes the yes/no of the target to numeric. I needed to do this as some models require the target to be numeric. The second cell takes all the category features and creates dummies with them. This is stock code I have used for long time (and I did not write it). It is nice because it will take any dataframe of any size and handle categorial features. I do not have to change a single line in it. It can be used generically on bascially any dataframe. Saves a lot of time of coding each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le_dep = preprocessing.LabelEncoder()\n",
    "#to convert into numbers\n",
    "df['churn'] = le_dep.fit_transform(df['churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform data transformation\n",
    "for col in df.columns[1:]:\n",
    "\tattName = col\n",
    "\tdType = df[col].dtype\n",
    "\tmissing = pd.isnull(df[col]).any()\n",
    "\tuniqueCount = len(df[attName].value_counts(normalize=False))\n",
    "\t# discretize (create dummies)\n",
    "\tif dType == object:\n",
    "\t\tdf = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "\t\tdel df[attName]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test/Train\n",
    "I split the data into a 60/40 train test. The features are stored in \"features_train\" and \"features_test\". The targets are in \"target_train\" and \"target_test\". I used a biggest test when I have an imbalanced set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split dataset into testing and training\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    df.ix[:,1:].values, df.ix[:,0].values, test_size=0.40, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a view of the size of each test/train set.\n",
    "Note there are now 73 features, and the test set is imbalanced (14.6%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 73)\n",
      "(3000, 73)\n",
      "(2000,)\n",
      "(3000,)\n",
      "Percent of Target that is Yes 0.146\n"
     ]
    }
   ],
   "source": [
    "print features_test.shape\n",
    "print features_train.shape\n",
    "print target_test.shape\n",
    "print target_train.shape\n",
    "print \"Percent of Target that is Yes\", target_test.mean()\n",
    "#data.groupby(['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Models\n",
    "All the models are done in Sci-Kit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Decision Tree\n",
    "I created a decision tree from the data. The accurancy of the model was 921%, while the test data classified at 92%. However notice that the \"yes\" class (the class I am interested in) only properly classified at 74% (specificity) and .71 (recall). That is so-so. Again, not uncommon with imbalanced data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy Score 0.9225\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Fail = no       0.96      0.95      0.95      1708\n",
      " Fail = yes       0.73      0.74      0.74       292\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree train model\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(features_train, target_train)\n",
    "#DT test model\n",
    "target_predicted_dt = clf.predict(features_test)\n",
    "print \"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt)\n",
    "# print classification report\n",
    "target_names = [\"Fail = no\", \"Fail = yes\"]\n",
    "print(classification_report(target_test, target_predicted_dt, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree.export_graphviz(clf, out_file='tree.dot')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation of Decision Tree\n",
    "I cross validated with 10 repeats. You can see the OOB score for each repeat and the mean. The mean is .92, which is quite close to the orginal model. I am not going to worry about over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.9269103   0.90697674  0.93023256  0.93355482  0.91362126  0.93311037\n",
      "  0.91638796  0.93311037  0.93645485  0.909699  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92400582228691408"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(clf, features_train, target_train, cv=10)\n",
    "print \"Cross Validation Score for each K\",scores\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visual of Confusion Matrix for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1635   73]\n",
      " [  85  207]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAADvCAYAAAAKNZpMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b8d9190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display confusion matrix\n",
    "cm = confusion_matrix(target_test, target_predicted_dt)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest\n",
    "Using the same data, I built a random forest with 500 bootstrapped trees. Notice I parallelized this to 4 cores as big random forest can be computationally expensive. \n",
    "\n",
    "My overall results went up by 3% over the decision tree. Also, my minory target precision, but the recall decresed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.95      1.00      0.97      1708\n",
      "Churn = yes       0.96      0.68      0.80       292\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2000\n",
      "\n",
      "[[1700    8]\n",
      " [  94  198]]\n"
     ]
    }
   ],
   "source": [
    "# train random forest model\n",
    "#paralleized to 4 cores \n",
    "rf = RandomForestClassifier(n_estimators= 500, n_jobs=-1,oob_score=True)\n",
    "rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_rf)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names))\n",
    "print(confusion_matrix(target_test, target_predicted_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation of Random Forest\n",
    "I cross validated with 10 repeats. You can see the OOB score for each repeat and the mean. The mean is .949, which is quite close to the orginal model. I am not going to worry about over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.94352159  0.94352159  0.94352159  0.95681063  0.94352159  0.94983278\n",
      "  0.94983278  0.94314381  0.94983278  0.95652174]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94800608895654404"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify RF with cross validation\n",
    "scores_rf = cross_val_score(rf, features_train, target_train, cv=10, n_jobs=-1)\n",
    "print \"Cross Validation Score for each K\",scores_rf\n",
    "scores_rf.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visual of Confusion Matrix for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1700    8]\n",
      " [  94  198]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAADvCAYAAAAKNZpMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c017fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display confusion matrix\n",
    "cm = confusion_matrix(target_test, target_predicted_rf)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Model Tuning\n",
    "You can tune any argument in these models. I did a grid search only on max_features (mtry in R). I parallelized the job to 4 cores for speed. You can see that max_features (mtry) of 5 had the best results. But frankly was very little difference from the other parameter results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.477776 seconds\n",
      "[mean: 0.88967, std: 0.00843, params: {'max_features': 2}, mean: 0.90167, std: 0.00765, params: {'max_features': 3}, mean: 0.91333, std: 0.00780, params: {'max_features': 4}, mean: 0.92200, std: 0.00719, params: {'max_features': 5}]\n"
     ]
    }
   ],
   "source": [
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_features\": [2, 3, 4, 5]}\n",
    "start_time = time.clock()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid,n_jobs=-1)\n",
    "\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "print time.clock() - start_time, \"seconds\"\n",
    "print grid_search.grid_scores_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#KNN\n",
    "I performed KNN on K=3 and K=5. For both K's the accurancy was 85% and 87% respectively and I still have problems with the minority class. KNN and Decision Tree perform about the same. I find this to be true frequently, which is why I use them as my base comparative models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.89      0.96      0.93      1708\n",
      "Churn = yes       0.59      0.31      0.41       292\n",
      "\n",
      "avg / total       0.85      0.87      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh3 = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh3.fit(features_train, target_train)\n",
    "# test KNN 3\n",
    "target_predicted_knn3 = neigh3.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_knn3)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_knn3, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.882\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.89      0.98      0.93      1708\n",
      "Churn = yes       0.74      0.30      0.42       292\n",
      "\n",
      "avg / total       0.87      0.88      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh5 = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh5.fit(features_train, target_train)\n",
    "# test KNN 3\n",
    "target_predicted_knn5 = neigh5.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_knn5)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_knn5, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#More Details\n",
    "Now that we know our random forest was the best model of the three I ran, I will gather some other information. Below is a non-ordered list of feature importance. I only showed 20 for purposes of space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('account_length', 0.033318535093387974),\n",
       " ('number_vmail_messages', 0.018210377903627221),\n",
       " ('total_day_minutes', 0.12258807653580045),\n",
       " ('total_day_calls', 0.03086787122158835),\n",
       " ('total_day_charge', 0.12792086150654633),\n",
       " ('total_eve_minutes', 0.054358523174774784),\n",
       " ('total_eve_calls', 0.028523412548850866),\n",
       " ('total_eve_charge', 0.05683329636728425),\n",
       " ('total_night_minutes', 0.037408110215462038),\n",
       " ('total_night_calls', 0.029950883876013211),\n",
       " ('total_night_charge', 0.037415725299857469),\n",
       " ('total_intl_minutes', 0.041080433790301497),\n",
       " ('total_intl_calls', 0.045613467088233516),\n",
       " ('total_intl_charge', 0.040579387340375798),\n",
       " ('number_customer_service_calls', 0.098426152784610282),\n",
       " ('state_AK', 0.00084384344555877731),\n",
       " ('state_AL', 0.00073451642763601986),\n",
       " ('state_AR', 0.0018380491950827462),\n",
       " ('state_AZ', 0.00174075694885328)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show importance of each feature in Random Forest\n",
    "zip(df.columns[1:20], rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ROC curve for Random Forest\n",
    "Finally a ROC curve that shows the lift I get from the Random Forest model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.922\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDzJbNChbPi0zAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b89be50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(target_test, rf.predict_proba(features_test)[:,1]) \n",
    "    \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print 'ROC AUC: %0.3f' % roc_auc\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Random Forest does the best, but I still am not getting the accurancy on my target class of interest. I have a few tricks I can do to work on this, but that is for another day/class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear SVM with L2 penalty, Cost function of 1 and auto class weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.87      0.98      0.92      1708\n",
      "        Yes       0.60      0.14      0.23       292\n",
      "\n",
      "avg / total       0.83      0.86      0.82      2000\n",
      "\n",
      "[[1681   27]\n",
      " [ 251   41]]\n",
      "0.861\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_linSVC=LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, class_weight='auto')\n",
    "clf_linSVC.fit(features_train, target_train)\n",
    "predicted_SVC=clf_linSVC.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVC,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVC))\n",
    "print accuracy_score(expected,predicted_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SVC kernel= linear\n",
    "#Change Class_Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.86      1.00      0.92      1708\n",
      "        Yes       1.00      0.01      0.02       292\n",
      "\n",
      "avg / total       0.88      0.86      0.79      2000\n",
      "\n",
      "[[1708    0]\n",
      " [ 289    3]]\n",
      "0.8555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=1.0,class_weight=None,gamma=0)\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.96      0.76      0.85      1708\n",
      "        Yes       0.36      0.80      0.50       292\n",
      "\n",
      "avg / total       0.87      0.77      0.80      2000\n",
      "\n",
      "[[1298  410]\n",
      " [  58  234]]\n",
      "0.766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=1.0,class_weight='auto',gamma=0)\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Grid Search of Cost Function (with cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [mean: 0.86167, std: 0.00000, params: {'C': 0.01}, mean: 0.86167, std: 0.00000, params: {'C': 0.05}, mean: 0.86200, std: 0.00067, params: {'C': 1}, mean: 0.86800, std: 0.00323, params: {'C': 2}, mean: 0.87000, std: 0.00408, params: {'C': 3}, mean: 0.87267, std: 0.00455, params: {'C': 4}, mean: 0.87167, std: 0.00350, params: {'C': 5}, mean: 0.87167, std: 0.00350, params: {'C': 9}, mean: 0.87300, std: 0.00386, params: {'C': 10}]\n",
      "BEST SCORE 0.873\n",
      "BEST PARAM {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "parameters = {'C':[.01,.05,1,2,3,4,5,9,10]}\n",
    "svr = SVC(kernel='linear')\n",
    "grid_svm = GridSearchCV(svr, parameters,n_jobs=-1, cv=5)\n",
    "grid_svm.fit(features_train, target_train)\n",
    "print \"SCORES\", grid_svm.grid_scores_\n",
    "print \"BEST SCORE\", grid_svm.best_score_\n",
    "print \"BEST PARAM\", grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Grid Search of Several Functions (with cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [mean: 0.86167, std: 0.00000, params: {'kernel': 'linear', 'C': 0.001}, mean: 0.86167, std: 0.00000, params: {'kernel': 'rbf', 'C': 0.001}, mean: 0.86167, std: 0.00000, params: {'kernel': 'linear', 'C': 0.01}, mean: 0.86167, std: 0.00000, params: {'kernel': 'rbf', 'C': 0.01}, mean: 0.86200, std: 0.00067, params: {'kernel': 'linear', 'C': 1}, mean: 0.86167, std: 0.00000, params: {'kernel': 'rbf', 'C': 1}, mean: 0.87000, std: 0.00408, params: {'kernel': 'linear', 'C': 3}, mean: 0.86167, std: 0.00000, params: {'kernel': 'rbf', 'C': 3}, mean: 0.87167, std: 0.00350, params: {'kernel': 'linear', 'C': 5}, mean: 0.86167, std: 0.00000, params: {'kernel': 'rbf', 'C': 5}, mean: 0.87300, std: 0.00386, params: {'kernel': 'linear', 'C': 10}, mean: 0.86167, std: 0.00000, params: {'kernel': 'rbf', 'C': 10}]\n",
      "BEST Estm SVC(C=10, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "BEST SCORE 0.873\n",
      "BEST PARAM {'kernel': 'linear', 'C': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[.001,.01,1,3,5,10]}\n",
    "svr = SVC()\n",
    "grid_svm = GridSearchCV(svr, parameters,n_jobs=-1, cv=5)\n",
    "grid_svm.fit(features_train, target_train)\n",
    "print \"SCORES\", grid_svm.grid_scores_\n",
    "print \"BEST Estm\",grid_svm.best_estimator_ \n",
    "print \"BEST SCORE\",grid_svm.best_score_\n",
    "print \"BEST PARAM\", grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#How does \"Best\" perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.95      0.74      0.83      1708\n",
      "        Yes       0.34      0.78      0.47       292\n",
      "\n",
      "avg / total       0.86      0.74      0.78      2000\n",
      "\n",
      "[[1256  452]\n",
      " [  63  229]]\n",
      "0.7425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=10.0,class_weight='auto',gamma=0)\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SVM using a RBF (non-linear) Kernel (High dimensional Space). Untuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.85      1.00      0.92      1708\n",
      "        Yes       0.00      0.00      0.00       292\n",
      "\n",
      "avg / total       0.73      0.85      0.79      2000\n",
      "\n",
      "[[1708    0]\n",
      " [ 292    0]]\n",
      "0.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mpgartland1/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_rbf = SVC(kernel='rbf', C=1.0,class_weight='auto',gamma=0.1)\n",
    "clf_rbf.fit(features_train, target_train)\n",
    "predicted_rbf=clf_rbf.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_rbf,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_rbf))\n",
    "print accuracy_score(expected,predicted_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SVM using Polynominal Kernel (2nd Degree), untuned.\n",
    "Would not fit at 2nd and 3rd degree given 24 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_poly = SVC(kernel='poly', degree=2, C=1.0,class_weight=None)\n",
    "clf_poly.fit(features_train, target_train)\n",
    "predicted_poly=clf_poly.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_poly,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_poly))\n",
    "print accuracy_score(expected,predicted_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
