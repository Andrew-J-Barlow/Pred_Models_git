{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Methods, SVMs, Tuning and CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like R, Python uses packages in data mining/machine learning. The 3 mose common ones are Pandas (manipulation), Scikit Learn (machine learning) and Matplotlit (graphics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mylesgartland/Documents/Courses/Predictive Models/Week 3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add packages\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "from sklearn import tree \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import scipy.stats as ss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import time\n",
    "from operator import itemgetter\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mylesgartland/Documents/Courses/Data Mining/Week 5\n"
     ]
    }
   ],
   "source": [
    "cd '/Users/mylesgartland/Documents/Courses/Data Mining/Week 5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data\n",
    "# Churn Calls Data\n",
    "This is a Pandas operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>1</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>175.2</td>\n",
       "      <td>74</td>\n",
       "      <td>29.78</td>\n",
       "      <td>151.7</td>\n",
       "      <td>79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>230.5</td>\n",
       "      <td>109</td>\n",
       "      <td>10.37</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>146.3</td>\n",
       "      <td>128</td>\n",
       "      <td>24.87</td>\n",
       "      <td>162.5</td>\n",
       "      <td>80</td>\n",
       "      <td>13.81</td>\n",
       "      <td>129.3</td>\n",
       "      <td>109</td>\n",
       "      <td>5.82</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>19</td>\n",
       "      <td>171.9</td>\n",
       "      <td>96</td>\n",
       "      <td>29.22</td>\n",
       "      <td>198.4</td>\n",
       "      <td>111</td>\n",
       "      <td>16.86</td>\n",
       "      <td>321.7</td>\n",
       "      <td>76</td>\n",
       "      <td>14.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>41</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>159.3</td>\n",
       "      <td>66</td>\n",
       "      <td>27.08</td>\n",
       "      <td>125.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.70</td>\n",
       "      <td>261.9</td>\n",
       "      <td>76</td>\n",
       "      <td>11.79</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>42</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>129</td>\n",
       "      <td>29.07</td>\n",
       "      <td>183.9</td>\n",
       "      <td>96</td>\n",
       "      <td>15.63</td>\n",
       "      <td>130.2</td>\n",
       "      <td>90</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AK</td>\n",
       "      <td>48</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>37</td>\n",
       "      <td>211.7</td>\n",
       "      <td>115</td>\n",
       "      <td>35.99</td>\n",
       "      <td>159.9</td>\n",
       "      <td>84</td>\n",
       "      <td>13.59</td>\n",
       "      <td>144.1</td>\n",
       "      <td>80</td>\n",
       "      <td>6.48</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AK</td>\n",
       "      <td>50</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>183.6</td>\n",
       "      <td>107</td>\n",
       "      <td>31.21</td>\n",
       "      <td>58.6</td>\n",
       "      <td>118</td>\n",
       "      <td>4.98</td>\n",
       "      <td>202.6</td>\n",
       "      <td>99</td>\n",
       "      <td>9.12</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AK</td>\n",
       "      <td>51</td>\n",
       "      <td>area_code_510</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>12</td>\n",
       "      <td>135.8</td>\n",
       "      <td>60</td>\n",
       "      <td>23.09</td>\n",
       "      <td>200.6</td>\n",
       "      <td>134</td>\n",
       "      <td>17.05</td>\n",
       "      <td>192.4</td>\n",
       "      <td>98</td>\n",
       "      <td>8.66</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>104</td>\n",
       "      <td>36.89</td>\n",
       "      <td>152.3</td>\n",
       "      <td>83</td>\n",
       "      <td>12.95</td>\n",
       "      <td>134.3</td>\n",
       "      <td>109</td>\n",
       "      <td>6.04</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>170.9</td>\n",
       "      <td>71</td>\n",
       "      <td>29.05</td>\n",
       "      <td>201.4</td>\n",
       "      <td>80</td>\n",
       "      <td>17.12</td>\n",
       "      <td>159.0</td>\n",
       "      <td>124</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account_length      area_code international_plan voice_mail_plan  \\\n",
       "0    AK               1  area_code_408                 no              no   \n",
       "1    AK              36  area_code_408                 no             yes   \n",
       "2    AK              36  area_code_415                yes             yes   \n",
       "3    AK              41  area_code_415                 no              no   \n",
       "4    AK              42  area_code_415                 no              no   \n",
       "5    AK              48  area_code_415                 no             yes   \n",
       "6    AK              50  area_code_408                 no              no   \n",
       "7    AK              51  area_code_510                yes             yes   \n",
       "8    AK              52  area_code_408                 no              no   \n",
       "9    AK              52  area_code_415                 no             yes   \n",
       "\n",
       "   number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "0                      0              175.2               74   \n",
       "1                     30              146.3              128   \n",
       "2                     19              171.9               96   \n",
       "3                      0              159.3               66   \n",
       "4                      0              171.0              129   \n",
       "5                     37              211.7              115   \n",
       "6                      0              183.6              107   \n",
       "7                     12              135.8               60   \n",
       "8                      0              217.0              104   \n",
       "9                     24              170.9               71   \n",
       "\n",
       "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "0             29.78              151.7               79             12.89   \n",
       "1             24.87              162.5               80             13.81   \n",
       "2             29.22              198.4              111             16.86   \n",
       "3             27.08              125.9               75             10.70   \n",
       "4             29.07              183.9               96             15.63   \n",
       "5             35.99              159.9               84             13.59   \n",
       "6             31.21               58.6              118              4.98   \n",
       "7             23.09              200.6              134             17.05   \n",
       "8             36.89              152.3               83             12.95   \n",
       "9             29.05              201.4               80             17.12   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                230.5                109               10.37   \n",
       "1                129.3                109                5.82   \n",
       "2                321.7                 76               14.48   \n",
       "3                261.9                 76               11.79   \n",
       "4                130.2                 90                5.86   \n",
       "5                144.1                 80                6.48   \n",
       "6                202.6                 99                9.12   \n",
       "7                192.4                 98                8.66   \n",
       "8                134.3                109                6.04   \n",
       "9                159.0                124                7.15   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                 5.3                 3               1.43   \n",
       "1                14.5                 6               3.92   \n",
       "2                10.5                 1               2.84   \n",
       "3                11.1                 5               3.00   \n",
       "4                 4.6                 6               1.24   \n",
       "5                12.2                 1               3.29   \n",
       "6                 8.7                 3               2.35   \n",
       "7                12.3                 7               3.32   \n",
       "8                11.8                 4               3.19   \n",
       "9                 4.1                 5               1.11   \n",
       "\n",
       "   number_customer_service_calls churn  \n",
       "0                              1    no  \n",
       "1                              0    no  \n",
       "2                              1   yes  \n",
       "3                              1    no  \n",
       "4                              0    no  \n",
       "5                              1    no  \n",
       "6                              1    no  \n",
       "7                              2    no  \n",
       "8                              2    no  \n",
       "9                              2    no  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv(\"Churn_Calls.csv\", sep=',')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'state', u'account_length', u'area_code', u'international_plan',\n",
      "       u'voice_mail_plan', u'number_vmail_messages', u'total_day_minutes',\n",
      "       u'total_day_calls', u'total_day_charge', u'total_eve_minutes',\n",
      "       u'total_eve_calls', u'total_eve_charge', u'total_night_minutes',\n",
      "       u'total_night_calls', u'total_night_charge', u'total_intl_minutes',\n",
      "       u'total_intl_calls', u'total_intl_charge',\n",
      "       u'number_customer_service_calls', u'churn'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# See each collum name\n",
    "print df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Target\n",
    "In this step I took the target variable and moved it to the first collum. I aslo made a reference to it called targetName. This just helps me with some below steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn</th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>international_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>1</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>175.2</td>\n",
       "      <td>74</td>\n",
       "      <td>29.78</td>\n",
       "      <td>151.7</td>\n",
       "      <td>79</td>\n",
       "      <td>12.89</td>\n",
       "      <td>230.5</td>\n",
       "      <td>109</td>\n",
       "      <td>10.37</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>146.3</td>\n",
       "      <td>128</td>\n",
       "      <td>24.87</td>\n",
       "      <td>162.5</td>\n",
       "      <td>80</td>\n",
       "      <td>13.81</td>\n",
       "      <td>129.3</td>\n",
       "      <td>109</td>\n",
       "      <td>5.82</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>AK</td>\n",
       "      <td>36</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>19</td>\n",
       "      <td>171.9</td>\n",
       "      <td>96</td>\n",
       "      <td>29.22</td>\n",
       "      <td>198.4</td>\n",
       "      <td>111</td>\n",
       "      <td>16.86</td>\n",
       "      <td>321.7</td>\n",
       "      <td>76</td>\n",
       "      <td>14.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>41</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>159.3</td>\n",
       "      <td>66</td>\n",
       "      <td>27.08</td>\n",
       "      <td>125.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.70</td>\n",
       "      <td>261.9</td>\n",
       "      <td>76</td>\n",
       "      <td>11.79</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>42</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>129</td>\n",
       "      <td>29.07</td>\n",
       "      <td>183.9</td>\n",
       "      <td>96</td>\n",
       "      <td>15.63</td>\n",
       "      <td>130.2</td>\n",
       "      <td>90</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>48</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>37</td>\n",
       "      <td>211.7</td>\n",
       "      <td>115</td>\n",
       "      <td>35.99</td>\n",
       "      <td>159.9</td>\n",
       "      <td>84</td>\n",
       "      <td>13.59</td>\n",
       "      <td>144.1</td>\n",
       "      <td>80</td>\n",
       "      <td>6.48</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>50</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>183.6</td>\n",
       "      <td>107</td>\n",
       "      <td>31.21</td>\n",
       "      <td>58.6</td>\n",
       "      <td>118</td>\n",
       "      <td>4.98</td>\n",
       "      <td>202.6</td>\n",
       "      <td>99</td>\n",
       "      <td>9.12</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>51</td>\n",
       "      <td>area_code_510</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>12</td>\n",
       "      <td>135.8</td>\n",
       "      <td>60</td>\n",
       "      <td>23.09</td>\n",
       "      <td>200.6</td>\n",
       "      <td>134</td>\n",
       "      <td>17.05</td>\n",
       "      <td>192.4</td>\n",
       "      <td>98</td>\n",
       "      <td>8.66</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_408</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>104</td>\n",
       "      <td>36.89</td>\n",
       "      <td>152.3</td>\n",
       "      <td>83</td>\n",
       "      <td>12.95</td>\n",
       "      <td>134.3</td>\n",
       "      <td>109</td>\n",
       "      <td>6.04</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no</td>\n",
       "      <td>AK</td>\n",
       "      <td>52</td>\n",
       "      <td>area_code_415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>170.9</td>\n",
       "      <td>71</td>\n",
       "      <td>29.05</td>\n",
       "      <td>201.4</td>\n",
       "      <td>80</td>\n",
       "      <td>17.12</td>\n",
       "      <td>159.0</td>\n",
       "      <td>124</td>\n",
       "      <td>7.15</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  churn state  account_length      area_code international_plan  \\\n",
       "0    no    AK               1  area_code_408                 no   \n",
       "1    no    AK              36  area_code_408                 no   \n",
       "2   yes    AK              36  area_code_415                yes   \n",
       "3    no    AK              41  area_code_415                 no   \n",
       "4    no    AK              42  area_code_415                 no   \n",
       "5    no    AK              48  area_code_415                 no   \n",
       "6    no    AK              50  area_code_408                 no   \n",
       "7    no    AK              51  area_code_510                yes   \n",
       "8    no    AK              52  area_code_408                 no   \n",
       "9    no    AK              52  area_code_415                 no   \n",
       "\n",
       "  voice_mail_plan  number_vmail_messages  total_day_minutes  total_day_calls  \\\n",
       "0              no                      0              175.2               74   \n",
       "1             yes                     30              146.3              128   \n",
       "2             yes                     19              171.9               96   \n",
       "3              no                      0              159.3               66   \n",
       "4              no                      0              171.0              129   \n",
       "5             yes                     37              211.7              115   \n",
       "6              no                      0              183.6              107   \n",
       "7             yes                     12              135.8               60   \n",
       "8              no                      0              217.0              104   \n",
       "9             yes                     24              170.9               71   \n",
       "\n",
       "   total_day_charge  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "0             29.78              151.7               79             12.89   \n",
       "1             24.87              162.5               80             13.81   \n",
       "2             29.22              198.4              111             16.86   \n",
       "3             27.08              125.9               75             10.70   \n",
       "4             29.07              183.9               96             15.63   \n",
       "5             35.99              159.9               84             13.59   \n",
       "6             31.21               58.6              118              4.98   \n",
       "7             23.09              200.6              134             17.05   \n",
       "8             36.89              152.3               83             12.95   \n",
       "9             29.05              201.4               80             17.12   \n",
       "\n",
       "   total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                230.5                109               10.37   \n",
       "1                129.3                109                5.82   \n",
       "2                321.7                 76               14.48   \n",
       "3                261.9                 76               11.79   \n",
       "4                130.2                 90                5.86   \n",
       "5                144.1                 80                6.48   \n",
       "6                202.6                 99                9.12   \n",
       "7                192.4                 98                8.66   \n",
       "8                134.3                109                6.04   \n",
       "9                159.0                124                7.15   \n",
       "\n",
       "   total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                 5.3                 3               1.43   \n",
       "1                14.5                 6               3.92   \n",
       "2                10.5                 1               2.84   \n",
       "3                11.1                 5               3.00   \n",
       "4                 4.6                 6               1.24   \n",
       "5                12.2                 1               3.29   \n",
       "6                 8.7                 3               2.35   \n",
       "7                12.3                 7               3.32   \n",
       "8                11.8                 4               3.19   \n",
       "9                 4.1                 5               1.11   \n",
       "\n",
       "   number_customer_service_calls  \n",
       "0                              1  \n",
       "1                              0  \n",
       "2                              1  \n",
       "3                              1  \n",
       "4                              0  \n",
       "5                              1  \n",
       "6                              1  \n",
       "7                              2  \n",
       "8                              2  \n",
       "9                              2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# designate target variable name\n",
    "targetName = 'churn'\n",
    "# move target variable into first column\n",
    "targetSeries = df[targetName]\n",
    "del df[targetName]\n",
    "df.insert(0, targetName, targetSeries)\n",
    "expected=targetName\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#EDA\n",
    "Just a touch of EDA. This is the distribution of the target. As you can see, the datset is imbalanced and the target class of interest \"yes\" is in the minority (a common occurance in classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x11489ce50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSWqcQS9JjTPoJalxBr0kNe7/A9HPOTMfL4IlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114869b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gb = df.groupby(targetName)\n",
    "targetEDA=gb[targetName].aggregate(len)\n",
    "plt.figure()\n",
    "targetEDA.plot(kind='bar', grid=False)\n",
    "plt.axhline(0, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Preprocessing\n",
    "The below two steps are for preprocessing. The first cell changes the yes/no of the target to numeric. I needed to do this as some models require the target to be numeric. The second cell takes all the category features and creates dummies with them. This is stock code I have used for long time (and I did not write it). It is nice because it will take any dataframe of any size and handle categorial features. I do not have to change a single line in it. It can be used generically on bascially any dataframe. Saves a lot of time of coding each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le_dep = preprocessing.LabelEncoder()\n",
    "#to convert into numbers\n",
    "df['churn'] = le_dep.fit_transform(df['churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform data transformation\n",
    "for col in df.columns[1:]:\n",
    "\tattName = col\n",
    "\tdType = df[col].dtype\n",
    "\tmissing = pd.isnull(df[col]).any()\n",
    "\tuniqueCount = len(df[attName].value_counts(normalize=False))\n",
    "\t# discretize (create dummies)\n",
    "\tif dType == object:\n",
    "\t\tdf = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "\t\tdel df[attName]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test/Train\n",
    "I split the data into a 60/40 train test. The features are stored in \"features_train\" and \"features_test\". The targets are in \"target_train\" and \"target_test\". I used a biggest test when I have an imbalanced set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split dataset into testing and training\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    df.ix[:,1:].values, df.ix[:,0].values, test_size=0.40, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a view of the size of each test/train set.\n",
    "Note there are now 73 features, and the test set is imbalanced (14.6%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 73)\n",
      "(3000, 73)\n",
      "(2000,)\n",
      "(3000,)\n",
      "Percent of Target that is Yes 0.146\n"
     ]
    }
   ],
   "source": [
    "print features_test.shape\n",
    "print features_train.shape\n",
    "print target_test.shape\n",
    "print target_train.shape\n",
    "print \"Percent of Target that is Yes\", target_test.mean()\n",
    "#data.groupby(['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Models\n",
    "All the models are done in Sci-Kit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Decision Tree\n",
    "I created a decision tree from the data. The accurancy of the model was 921%, while the test data classified at 92%. However notice that the \"yes\" class (the class I am interested in) only properly classified at 74% (specificity) and .71 (recall). That is so-so. Again, not uncommon with imbalanced data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy Score 0.926\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Fail = no       0.96      0.96      0.96      1708\n",
      " Fail = yes       0.75      0.74      0.74       292\n",
      "\n",
      "avg / total       0.93      0.93      0.93      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree train model\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(features_train, target_train)\n",
    "#DT test model\n",
    "target_predicted_dt = clf.predict(features_test)\n",
    "print \"DT Accuracy Score\", accuracy_score(target_test, target_predicted_dt)\n",
    "# print classification report\n",
    "target_names = [\"Fail = no\", \"Fail = yes\"]\n",
    "print(classification_report(target_test, target_predicted_dt, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation of Decision Tree\n",
    "I cross validated with 10 repeats. You can see the OOB score for each repeat and the mean. The mean is .92, which is quite close to the orginal model. I am not going to worry about over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.91694352  0.89700997  0.93023256  0.94019934  0.910299    0.93311037\n",
      "  0.9264214   0.92307692  0.9264214   0.91638796]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92201024455827285"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(clf, features_train, target_train, cv=10)\n",
    "print \"Cross Validation Score for each K\",scores\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visual of Confusion Matrix for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1632   76]\n",
      " [  77  215]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAADvCAYAAAAD3jo2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5sBhZqU5cJhZaQ4cZlaaA4eZlfafXkF+14y4lrYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108ab0390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display confusion matrix\n",
    "cm = confusion_matrix(target_test, target_predicted_dt)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest\n",
    "Using the same data, I built a random forest with 500 bootstrapped trees. Notice I parallelized this to 4 cores as big random forest can be computationally expensive. \n",
    "\n",
    "My overall results went up by 3% over the decision tree. Also, my minory target precision, but the recall decresed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.95      0.99      0.97      1708\n",
      "Churn = yes       0.95      0.69      0.80       292\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2000\n",
      "\n",
      "[[1698   10]\n",
      " [  91  201]]\n"
     ]
    }
   ],
   "source": [
    "# train random forest model\n",
    "#paralleized to 4 cores \n",
    "rf = RandomForestClassifier(n_estimators= 500, n_jobs=-1,oob_score=True)\n",
    "rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_rf)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names))\n",
    "print(confusion_matrix(target_test, target_predicted_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation of Random Forest\n",
    "I cross validated with 10 repeats. You can see the OOB score for each repeat and the mean. The mean is .949, which is quite close to the orginal model. I am not going to worry about over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [ 0.94019934  0.94352159  0.95016611  0.96013289  0.94019934  0.94314381\n",
      "  0.95317726  0.94314381  0.94314381  0.95986622]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94766941854909492"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify RF with cross validation\n",
    "scores_rf = cross_val_score(rf, features_train, target_train, cv=10, n_jobs=-1)\n",
    "print \"Cross Validation Score for each K\",scores_rf\n",
    "scores_rf.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visual of Confusion Matrix for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1700    8]\n",
      " [  94  198]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAADvCAYAAAAKNZpMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c017fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display confusion matrix\n",
    "cm = confusion_matrix(target_test, target_predicted_rf)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Model Tuning\n",
    "You can tune any argument in these models. I did a grid search only on max_features (mtry in R). I parallelized the job to 4 cores for speed. You can see that max_features (mtry) of 5 had the best results. But frankly was very little difference from the other parameter results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.477776 seconds\n",
      "[mean: 0.88967, std: 0.00843, params: {'max_features': 2}, mean: 0.90167, std: 0.00765, params: {'max_features': 3}, mean: 0.91333, std: 0.00780, params: {'max_features': 4}, mean: 0.92200, std: 0.00719, params: {'max_features': 5}]\n"
     ]
    }
   ],
   "source": [
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_features\": [2, 3, 4, 5]}\n",
    "start_time = time.clock()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid,n_jobs=-1)\n",
    "\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "print time.clock() - start_time, \"seconds\"\n",
    "print grid_search.grid_scores_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#KNN\n",
    "I performed KNN on K=3 and K=5. For both K's the accurancy was 85% and 87% respectively and I still have problems with the minority class. KNN and Decision Tree perform about the same. I find this to be true frequently, which is why I use them as my base comparative models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.89      0.96      0.93      1708\n",
      "Churn = yes       0.59      0.31      0.41       292\n",
      "\n",
      "avg / total       0.85      0.87      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh3 = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh3.fit(features_train, target_train)\n",
    "# test KNN 3\n",
    "target_predicted_knn3 = neigh3.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_knn3)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_knn3, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.882\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Churn = no       0.89      0.98      0.93      1708\n",
      "Churn = yes       0.74      0.30      0.42       292\n",
      "\n",
      "avg / total       0.87      0.88      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh5 = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh5.fit(features_train, target_train)\n",
    "# test KNN 3\n",
    "target_predicted_knn5 = neigh5.predict(features_test)\n",
    "print accuracy_score(target_test, target_predicted_knn5)\n",
    "target_names = [\"Churn = no\", \"Churn = yes\"]\n",
    "print(classification_report(target_test, target_predicted_knn5, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#More Details\n",
    "Now that we know our random forest was the best model of the three I ran, I will gather some other information. Below is a non-ordered list of feature importance. I only showed 20 for purposes of space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('account_length', 0.033318535093387974),\n",
       " ('number_vmail_messages', 0.018210377903627221),\n",
       " ('total_day_minutes', 0.12258807653580045),\n",
       " ('total_day_calls', 0.03086787122158835),\n",
       " ('total_day_charge', 0.12792086150654633),\n",
       " ('total_eve_minutes', 0.054358523174774784),\n",
       " ('total_eve_calls', 0.028523412548850866),\n",
       " ('total_eve_charge', 0.05683329636728425),\n",
       " ('total_night_minutes', 0.037408110215462038),\n",
       " ('total_night_calls', 0.029950883876013211),\n",
       " ('total_night_charge', 0.037415725299857469),\n",
       " ('total_intl_minutes', 0.041080433790301497),\n",
       " ('total_intl_calls', 0.045613467088233516),\n",
       " ('total_intl_charge', 0.040579387340375798),\n",
       " ('number_customer_service_calls', 0.098426152784610282),\n",
       " ('state_AK', 0.00084384344555877731),\n",
       " ('state_AL', 0.00073451642763601986),\n",
       " ('state_AR', 0.0018380491950827462),\n",
       " ('state_AZ', 0.00174075694885328)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show importance of each feature in Random Forest\n",
    "zip(df.columns[1:20], rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ROC curve for Random Forest\n",
    "Finally a ROC curve that shows the lift I get from the Random Forest model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.922\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDzJbNChbPi0zAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b89be50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(target_test, rf.predict_proba(features_test)[:,1]) \n",
    "    \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print 'ROC AUC: %0.3f' % roc_auc\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Random Forest does the best, but I still am not getting the accurancy on my target class of interest. I have a few tricks I can do to work on this, but that is for another day/class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear SVM with L2 penalty, Cost function of 1 and auto class weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.85      1.00      0.92      1708\n",
      "        Yes       1.00      0.01      0.01       292\n",
      "\n",
      "avg / total       0.88      0.85      0.79      2000\n",
      "\n",
      "[[1708    0]\n",
      " [ 290    2]]\n",
      "0.855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_linSVC=LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, class_weight='auto')\n",
    "clf_linSVC.fit(features_train, target_train)\n",
    "predicted_SVC=clf_linSVC.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVC,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVC))\n",
    "print accuracy_score(expected,predicted_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SVC kernel= linear\n",
    "#Change Class_Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.86      1.00      0.92      1708\n",
      "        Yes       1.00      0.01      0.02       292\n",
      "\n",
      "avg / total       0.88      0.86      0.79      2000\n",
      "\n",
      "[[1708    0]\n",
      " [ 289    3]]\n",
      "0.8555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=1.0,class_weight=None,gamma=0)\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.96      0.76      0.85      1708\n",
      "        Yes       0.36      0.80      0.50       292\n",
      "\n",
      "avg / total       0.87      0.77      0.80      2000\n",
      "\n",
      "[[1298  410]\n",
      " [  58  234]]\n",
      "0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sklearn/svm/base.py:85: DeprecationWarning: gamma=0.0 has been deprecated in favor of gamma='auto' as of 0.17. Backward compatibility for gamma=0.0 will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.py:62: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n",
      "  \" 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=1.0,class_weight='auto',gamma=0)\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Grid Search of Cost Function (with cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [mean: 0.86167, std: 0.00000, params: {'C': 0.01}, mean: 0.86167, std: 0.00000, params: {'C': 0.05}, mean: 0.86200, std: 0.00067, params: {'C': 1}, mean: 0.86800, std: 0.00323, params: {'C': 2}, mean: 0.87000, std: 0.00408, params: {'C': 3}, mean: 0.87267, std: 0.00455, params: {'C': 4}, mean: 0.87167, std: 0.00350, params: {'C': 5}, mean: 0.87167, std: 0.00350, params: {'C': 9}, mean: 0.87300, std: 0.00386, params: {'C': 10}]\n",
      "BEST SCORE 0.873\n",
      "BEST PARAM {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "parameters = {'C':[.01,.05,1,2,3,4,5,9,10]}\n",
    "svr = SVC(kernel='linear')\n",
    "grid_svm = GridSearchCV(svr, parameters,n_jobs=-1, cv=5)\n",
    "grid_svm.fit(features_train, target_train)\n",
    "print \"SCORES\", grid_svm.grid_scores_\n",
    "print \"BEST SCORE\", grid_svm.best_score_\n",
    "print \"BEST PARAM\", grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Grid Search of Several Functions (with cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [mean: 0.86167, std: 0.00000, params: {'kernel': 'linear', 'C': 0.001}, mean: 0.86167, std: 0.00000, params: {'kernel': 'rbf', 'C': 0.001}, mean: 0.86167, std: 0.00000, params: {'kernel': 'linear', 'C': 0.01}, mean: 0.86167, std: 0.00000, params: {'kernel': 'rbf', 'C': 0.01}, mean: 0.86200, std: 0.00067, params: {'kernel': 'linear', 'C': 1}, mean: 0.86167, std: 0.00000, params: {'kernel': 'rbf', 'C': 1}, mean: 0.87000, std: 0.00408, params: {'kernel': 'linear', 'C': 3}, mean: 0.86167, std: 0.00000, params: {'kernel': 'rbf', 'C': 3}, mean: 0.87167, std: 0.00350, params: {'kernel': 'linear', 'C': 5}, mean: 0.86167, std: 0.00000, params: {'kernel': 'rbf', 'C': 5}, mean: 0.87300, std: 0.00386, params: {'kernel': 'linear', 'C': 10}, mean: 0.86167, std: 0.00000, params: {'kernel': 'rbf', 'C': 10}]\n",
      "BEST Estm SVC(C=10, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "BEST SCORE 0.873\n",
      "BEST PARAM {'kernel': 'linear', 'C': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[.001,.01,1,3,5,10]}\n",
    "svr = SVC()\n",
    "grid_svm = GridSearchCV(svr, parameters,n_jobs=-1, cv=5)\n",
    "grid_svm.fit(features_train, target_train)\n",
    "print \"SCORES\", grid_svm.grid_scores_\n",
    "print \"BEST Estm\",grid_svm.best_estimator_ \n",
    "print \"BEST SCORE\",grid_svm.best_score_\n",
    "print \"BEST PARAM\", grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#How does \"Best\" perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.95      0.74      0.83      1708\n",
      "        Yes       0.34      0.78      0.47       292\n",
      "\n",
      "avg / total       0.86      0.74      0.78      2000\n",
      "\n",
      "[[1256  452]\n",
      " [  63  229]]\n",
      "0.7425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_lin = SVC(kernel='linear', C=10.0,class_weight='auto',gamma=0)\n",
    "clf_lin.fit(features_train, target_train)\n",
    "predicted_SVM=clf_lin.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "print accuracy_score(expected,predicted_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SVM using a RBF (non-linear) Kernel (High dimensional Space). Untuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.85      1.00      0.92      1708\n",
      "        Yes       0.00      0.00      0.00       292\n",
      "\n",
      "avg / total       0.73      0.85      0.79      2000\n",
      "\n",
      "[[1708    0]\n",
      " [ 292    0]]\n",
      "0.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mpgartland1/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_rbf = SVC(kernel='rbf', C=1.0,class_weight='auto',gamma=0.1)\n",
    "clf_rbf.fit(features_train, target_train)\n",
    "predicted_rbf=clf_rbf.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_rbf,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_rbf))\n",
    "print accuracy_score(expected,predicted_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SVM using Polynominal Kernel (2nd Degree), untuned.\n",
    "Would not fit at 2nd and 3rd degree given 24 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.svm import SVC\n",
    "#standard linear SVC\n",
    "clf_poly = SVC(kernel='poly', degree=2, C=1.0,class_weight=None)\n",
    "clf_poly.fit(features_train, target_train)\n",
    "predicted_poly=clf_poly.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_poly,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_poly))\n",
    "print accuracy_score(expected,predicted_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.92      0.95      0.93      1708\n",
      "        Yes       0.64      0.50      0.56       292\n",
      "\n",
      "avg / total       0.88      0.89      0.88      2000\n",
      "\n",
      "[[1624   84]\n",
      " [ 145  147]]\n",
      "0.8855\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boost Classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf_GBC = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "clf_GBC.fit(features_train, target_train)\n",
    "predicted_GBC=clf_GBC.predict(features_test)\n",
    "expected = target_test\n",
    "print(classification_report(expected, predicted_GBC,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_GBC))\n",
    "print accuracy_score(expected,predicted_GBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.96      0.98      0.97      1708\n",
      "        Yes       0.89      0.74      0.81       292\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2000\n",
      "\n",
      "[[1680   28]\n",
      " [  76  216]]\n",
      "0.948\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost of a Decision Tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)\n",
    "bdt.fit(features_train, target_train)\n",
    "predicted_bdt=bdt.predict(features_test)\n",
    "expected = target_test\n",
    "print(classification_report(expected, predicted_bdt,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_bdt))\n",
    "print accuracy_score(expected,predicted_bdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from sknn.mlp import Classifier, Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "('The following error happened while compiling the node', Dot22(X, W), '\\n', 'dlopen(/Users/mylesgartland/.theano/compiledir_Darwin-15.3.0-x86_64-i386-64bit-i386-2.7.11-64/tmpJkU6gl/eb163660e6e45b373cd7909e14efd44a.so, 2): Library not loaded: libmkl_intel_lp64.dylib\\n  Referenced from: /Users/mylesgartland/.theano/compiledir_Darwin-15.3.0-x86_64-i386-64bit-i386-2.7.11-64/tmpJkU6gl/eb163660e6e45b373cd7909e14efd44a.so\\n  Reason: image not found', '[Dot22(X, W)]')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8669288e781e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     n_iter=10)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sknn/mlp.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, w)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;31m# Now train based on a problem transformed into regression.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sknn/mlp.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, w)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training on dataset of {:,} samples with {:,} total size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sknn/mlp.pyc\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, X, y, w)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiLayerPerceptronBackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sknn/backend/lasagne/mlp.pyc\u001b[0m in \u001b[0;36m_initialize_impl\u001b[0;34m(self, X, y, w)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Can do partial initialization when predicting, no trainer needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/sknn/backend/lasagne/mlp.pyc\u001b[0m in \u001b[0;36m_create_mlp\u001b[0;34m(self, X, w)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_input_downcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_conv_transpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mallow_input_downcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_input_downcast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                 profile=profile)\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;31m# borrowed used defined inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    509\u001b[0m     return orig_function(inputs, cloned_outputs, mode,\n\u001b[1;32m    510\u001b[0m             \u001b[0maccept_inplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             on_unused_input=on_unused_input)\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[0;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input)\u001b[0m\n\u001b[1;32m   1464\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m                        defaults)\n\u001b[0m\u001b[1;32m   1467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m     \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, input_storage, trustme)\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m             _fn, _i, _o = self.linker.make_thunk(\n\u001b[0;32m-> 1324\u001b[0;31m                 input_storage=input_storage_lists)\n\u001b[0m\u001b[1;32m   1325\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlimit_orig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, input_storage, output_storage)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_thunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         return self.make_all(input_storage=input_storage,\n\u001b[0;32m--> 519\u001b[0;31m                              output_storage=output_storage)[:3]\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/theano/gof/vm.pyc\u001b[0m in \u001b[0;36mmake_all\u001b[0;34m(self, profiler, input_storage, output_storage)\u001b[0m\n\u001b[1;32m    895\u001b[0m                                                  \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m                                                  \u001b[0mcompute_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m                                                  no_recycling))\n\u001b[0m\u001b[1;32m    898\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lazy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                     \u001b[0;31m# We don't want all ops maker to think about lazy Ops.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trying CLinker.make_thunk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m                 outputs = cl.make_thunk(input_storage=node_input_storage,\n\u001b[0;32m--> 739\u001b[0;31m                                         output_storage=node_output_storage)\n\u001b[0m\u001b[1;32m    740\u001b[0m                 \u001b[0mfill_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_input_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_output_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, input_storage, output_storage, keep_lock)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         cthunk, in_storage, out_storage, error_storage = self.__compile__(\n\u001b[1;32m   1072\u001b[0m             \u001b[0minput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m             keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CThunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcthunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36m__compile__\u001b[0;34m(self, input_storage, output_storage, keep_lock)\u001b[0m\n\u001b[1;32m   1013\u001b[0m                                     \u001b[0minput_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m                                     \u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m                                     keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1016\u001b[0m         return (thunk,\n\u001b[1;32m   1017\u001b[0m                 [link.Container(input, storage) for input, storage in\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36mcthunk_factory\u001b[0;34m(self, error_storage, in_storage, out_storage, keep_lock)\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m             module = get_module_cache().module_from_key(\n\u001b[0;32m-> 1442\u001b[0;31m                 key=key, lnk=self, keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0mvars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morphans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/theano/gof/cmodule.pyc\u001b[0m in \u001b[0;36mmodule_from_key\u001b[0;34m(self, key, lnk, keep_lock)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlimport_workdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlnk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_cmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36mcompile_cmodule\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 \u001b[0mlib_dirs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m                 \u001b[0mlibs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m                 preargs=preargs)\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/theano/gof/cmodule.pyc\u001b[0m in \u001b[0;36mcompile_str\u001b[0;34m(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module)\u001b[0m\n\u001b[1;32m   2017\u001b[0m             \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__init__.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2019\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdlimport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mylesgartland/anaconda/lib/python2.7/site-packages/theano/gof/cmodule.pyc\u001b[0m in \u001b[0;36mdlimport\u001b[0;34m(fullpath, suffix)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvalidate_caches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mimport_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: ('The following error happened while compiling the node', Dot22(X, W), '\\n', 'dlopen(/Users/mylesgartland/.theano/compiledir_Darwin-15.3.0-x86_64-i386-64bit-i386-2.7.11-64/tmpJkU6gl/eb163660e6e45b373cd7909e14efd44a.so, 2): Library not loaded: libmkl_intel_lp64.dylib\\n  Referenced from: /Users/mylesgartland/.theano/compiledir_Darwin-15.3.0-x86_64-i386-64bit-i386-2.7.11-64/tmpJkU6gl/eb163660e6e45b373cd7909e14efd44a.so\\n  Reason: image not found', '[Dot22(X, W)]')"
     ]
    }
   ],
   "source": [
    "nn = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Sigmoid\", units=100),\n",
    "        Layer(\"Softmax\")],\n",
    "    learning_rate=0.02,\n",
    "    n_iter=10)\n",
    "nn.fit(features_train, target_train)\n",
    "\n",
    "y_valid = nn.predict(features_test)\n",
    "\n",
    "score = nn.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
